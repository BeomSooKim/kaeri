{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import platform\n",
    "plt.style.use('seaborn')\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "from metric import E1_loss, E2_loss, total_loss\n",
    "from models import classifier, cnn_model, conv_block, cnn_parallel\n",
    "from utils import train_model, eval_model, dfDataset, weights_init\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'XY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fc = classifier([128, 64, 32, 16], input_size = 512*3*5, output_size = len(name))\n",
    "conv1 = conv_block([8, 16, 32, 64, 128], [1, 375, 5], (3, 1)).cuda() # 128 * 9 * 5\n",
    "conv2 = conv_block([8, 16, 32, 64, 128], [1, 375, 5], (4, 1)).cuda() # 128 * 8 * 5\n",
    "conv3 = conv_block([8, 16, 32, 64, 128], [1, 375, 5], (5, 1)).cuda() # 128 * 7 * 5\n",
    "conv4 = conv_block([8, 16, 32, 64, 128], [1, 375, 5], (6, 1)).cuda() # 128 * 6 * 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = classifier([128, 64, 32, 16], input_size = 128*30*5, output_size = len(name)).cuda()\n",
    "fc = fc.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_parallel([conv1, conv2, conv3, conv4], fc).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- parallel cnn 구현\n",
    "- lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 100\n",
    "base_lr = 0.001\n",
    "now = datetime.strftime(datetime.now(), '%Y%m%d-%H%M%S')\n",
    "save_path = './model/{}'.format(now)\n",
    "initialize = True\n",
    "print_summary = True\n",
    "batch_size = 256\n",
    "nfold = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == 'Windows':\n",
    "    root_dir = 'D:/datasets/KAERI_dataset/'\n",
    "else:\n",
    "    root_dir = '/home/bskim/project/kaeri/KAERI_dataset/'\n",
    "\n",
    "train_f = pd.read_csv(os.path.join(root_dir, 'train_features.csv'))\n",
    "train_t = pd.read_csv(os.path.join(root_dir, 'train_target.csv'))\n",
    "test_f = pd.read_csv(os.path.join(root_dir, 'test_features.csv'))\n",
    "\n",
    "train_f = train_f[['Time','S1','S2','S3','S4']].values\n",
    "train_f = train_f.reshape((-1, 1, 375, 5))#.astype(np.float32)\n",
    "\n",
    "test_f = test_f[['Time','S1','S2','S3','S4']].values\n",
    "test_f = test_f.reshape((-1, 1, 375, 5))#.astype(np.float32)\n",
    "test_f = torch.FloatTensor(test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XY train...\n",
      "fold 1\n",
      "[1] : train loss 2.501864, val loss drop 10000000.0000 to 1.3084\n",
      "[2] : train loss 0.633959, val loss drop 1.3084 to 0.2824\n",
      "[3] : train loss 0.110936, val loss drop 0.2824 to 0.1545\n",
      "[4] : train loss 0.035003, val loss drop 0.1545 to 0.0771\n",
      "[5] : train loss 0.015269, val loss drop 0.0771 to 0.0132\n",
      "[6] : train loss 0.008287, val loss drop 0.0132 to 0.0081\n",
      "[9] : train loss 0.002394, val loss drop 0.0081 to 0.0046\n",
      "[11] : train loss 0.001811, val loss drop 0.0046 to 0.0028\n",
      "[12] : train loss 0.001871, val loss drop 0.0028 to 0.0025\n",
      "[14] : train loss 0.001097, val loss drop 0.0025 to 0.0018\n",
      "[17] : train loss 0.001915, val loss drop 0.0018 to 0.0016\n",
      "[19] : train loss 0.001377, val loss drop 0.0016 to 0.0014\n",
      "[21] : train loss 0.000572, val loss drop 0.0014 to 0.0013\n",
      "[22] : train loss 0.000773, val loss drop 0.0013 to 0.0008\n",
      "[37] : train loss 0.000686, val loss drop 0.0008 to 0.0006\n",
      "[57] : train loss 0.000350, val loss drop 0.0006 to 0.0006\n",
      "[85] : train loss 0.000409, val loss drop 0.0006 to 0.0005\n",
      "[98] : train loss 0.000286, val loss drop 0.0005 to 0.0004\n",
      "fold 2\n",
      "[1] : train loss 2.546064, val loss drop 10000000.0000 to 1.3873\n",
      "[2] : train loss 0.799201, val loss drop 1.3873 to 0.2972\n",
      "[3] : train loss 0.158430, val loss drop 0.2972 to 0.0777\n",
      "[4] : train loss 0.053426, val loss drop 0.0777 to 0.0579\n",
      "[5] : train loss 0.024419, val loss drop 0.0579 to 0.0558\n",
      "[6] : train loss 0.013854, val loss drop 0.0558 to 0.0332\n",
      "[7] : train loss 0.009007, val loss drop 0.0332 to 0.0065\n",
      "[8] : train loss 0.005824, val loss drop 0.0065 to 0.0058\n",
      "[9] : train loss 0.003578, val loss drop 0.0058 to 0.0033\n",
      "[10] : train loss 0.002389, val loss drop 0.0033 to 0.0027\n",
      "[13] : train loss 0.001938, val loss drop 0.0027 to 0.0020\n",
      "[14] : train loss 0.001500, val loss drop 0.0020 to 0.0018\n",
      "[15] : train loss 0.001687, val loss drop 0.0018 to 0.0016\n",
      "[23] : train loss 0.000874, val loss drop 0.0016 to 0.0012\n",
      "[29] : train loss 0.001809, val loss drop 0.0012 to 0.0010\n",
      "[38] : train loss 0.000644, val loss drop 0.0010 to 0.0010\n",
      "[40] : train loss 0.001219, val loss drop 0.0010 to 0.0006\n",
      "[60] : train loss 0.000740, val loss drop 0.0006 to 0.0006\n",
      "[61] : train loss 0.000302, val loss drop 0.0006 to 0.0005\n",
      "[72] : train loss 0.000470, val loss drop 0.0005 to 0.0004\n",
      "[78] : train loss 0.000344, val loss drop 0.0004 to 0.0004\n",
      "fold 3\n",
      "[1] : train loss 2.638360, val loss drop 10000000.0000 to 1.6898\n",
      "[2] : train loss 1.313920, val loss drop 1.6898 to 0.9783\n",
      "[3] : train loss 0.820515, val loss drop 0.9783 to 0.5959\n",
      "[4] : train loss 0.520166, val loss drop 0.5959 to 0.3111\n",
      "[5] : train loss 0.216631, val loss drop 0.3111 to 0.0870\n",
      "[7] : train loss 0.025888, val loss drop 0.0870 to 0.0192\n",
      "[8] : train loss 0.013118, val loss drop 0.0192 to 0.0090\n",
      "[10] : train loss 0.004847, val loss drop 0.0090 to 0.0049\n",
      "[13] : train loss 0.002274, val loss drop 0.0049 to 0.0043\n",
      "[16] : train loss 0.003033, val loss drop 0.0043 to 0.0024\n",
      "[17] : train loss 0.002086, val loss drop 0.0024 to 0.0022\n",
      "[18] : train loss 0.001608, val loss drop 0.0022 to 0.0017\n",
      "[31] : train loss 0.001225, val loss drop 0.0017 to 0.0016\n",
      "[32] : train loss 0.000958, val loss drop 0.0016 to 0.0010\n",
      "[33] : train loss 0.002329, val loss drop 0.0010 to 0.0009\n",
      "[47] : train loss 0.000903, val loss drop 0.0009 to 0.0006\n",
      "[71] : train loss 0.000530, val loss drop 0.0006 to 0.0004\n",
      "[92] : train loss 0.000727, val loss drop 0.0004 to 0.0004\n",
      "fold 4\n",
      "[1] : train loss 2.511174, val loss drop 10000000.0000 to 1.2236\n",
      "[2] : train loss 1.454366, val loss drop 1.2236 to 1.0838\n",
      "[3] : train loss 1.120291, val loss drop 1.0838 to 0.9036\n",
      "[4] : train loss 0.796960, val loss drop 0.9036 to 0.4706\n",
      "[5] : train loss 0.407540, val loss drop 0.4706 to 0.1475\n",
      "[6] : train loss 0.116873, val loss drop 0.1475 to 0.0935\n",
      "[7] : train loss 0.045640, val loss drop 0.0935 to 0.0154\n",
      "[11] : train loss 0.004907, val loss drop 0.0154 to 0.0053\n",
      "[17] : train loss 0.001867, val loss drop 0.0053 to 0.0016\n",
      "[22] : train loss 0.001217, val loss drop 0.0016 to 0.0011\n",
      "[39] : train loss 0.001217, val loss drop 0.0011 to 0.0009\n",
      "[71] : train loss 0.001415, val loss drop 0.0009 to 0.0007\n",
      "[76] : train loss 0.000362, val loss drop 0.0007 to 0.0005\n",
      "fold 5\n",
      "[1] : train loss 2.396670, val loss drop 10000000.0000 to 1.1162\n",
      "[2] : train loss 0.517294, val loss drop 1.1162 to 0.3842\n",
      "[3] : train loss 0.144430, val loss drop 0.3842 to 0.1566\n",
      "[4] : train loss 0.051427, val loss drop 0.1566 to 0.0855\n",
      "[5] : train loss 0.023060, val loss drop 0.0855 to 0.0223\n",
      "[7] : train loss 0.007368, val loss drop 0.0223 to 0.0146\n",
      "[8] : train loss 0.004844, val loss drop 0.0146 to 0.0120\n",
      "[9] : train loss 0.003656, val loss drop 0.0120 to 0.0092\n",
      "[10] : train loss 0.002823, val loss drop 0.0092 to 0.0049\n",
      "[14] : train loss 0.002009, val loss drop 0.0049 to 0.0038\n",
      "[16] : train loss 0.001594, val loss drop 0.0038 to 0.0030\n",
      "[18] : train loss 0.001532, val loss drop 0.0030 to 0.0017\n",
      "[24] : train loss 0.001944, val loss drop 0.0017 to 0.0012\n",
      "[39] : train loss 0.001410, val loss drop 0.0012 to 0.0010\n",
      "[45] : train loss 0.001056, val loss drop 0.0010 to 0.0010\n",
      "[48] : train loss 0.000809, val loss drop 0.0010 to 0.0008\n",
      "[59] : train loss 0.000872, val loss drop 0.0008 to 0.0007\n",
      "[73] : train loss 0.000736, val loss drop 0.0007 to 0.0005\n",
      "fold 6\n",
      "[1] : train loss 2.616734, val loss drop 10000000.0000 to 1.6341\n",
      "[2] : train loss 0.848135, val loss drop 1.6341 to 0.4394\n",
      "[3] : train loss 0.179381, val loss drop 0.4394 to 0.0888\n",
      "[4] : train loss 0.062663, val loss drop 0.0888 to 0.0368\n",
      "[5] : train loss 0.024818, val loss drop 0.0368 to 0.0326\n",
      "[7] : train loss 0.007084, val loss drop 0.0326 to 0.0264\n",
      "[8] : train loss 0.004527, val loss drop 0.0264 to 0.0108\n",
      "[9] : train loss 0.003295, val loss drop 0.0108 to 0.0083\n",
      "[10] : train loss 0.002577, val loss drop 0.0083 to 0.0082\n",
      "[11] : train loss 0.002159, val loss drop 0.0082 to 0.0062\n",
      "[12] : train loss 0.001924, val loss drop 0.0062 to 0.0032\n",
      "[14] : train loss 0.001392, val loss drop 0.0032 to 0.0022\n",
      "[21] : train loss 0.001166, val loss drop 0.0022 to 0.0010\n",
      "[40] : train loss 0.001457, val loss drop 0.0010 to 0.0008\n",
      "[44] : train loss 0.000637, val loss drop 0.0008 to 0.0008\n",
      "[57] : train loss 0.000298, val loss drop 0.0008 to 0.0005\n",
      "fold 7\n",
      "[1] : train loss 2.528105, val loss drop 10000000.0000 to 1.2867\n",
      "[2] : train loss 1.181101, val loss drop 1.2867 to 0.6536\n",
      "[3] : train loss 0.390425, val loss drop 0.6536 to 0.4345\n",
      "[4] : train loss 0.085695, val loss drop 0.4345 to 0.2279\n",
      "[5] : train loss 0.031489, val loss drop 0.2279 to 0.0291\n",
      "[6] : train loss 0.017307, val loss drop 0.0291 to 0.0139\n",
      "[7] : train loss 0.009629, val loss drop 0.0139 to 0.0118\n",
      "[9] : train loss 0.006680, val loss drop 0.0118 to 0.0042\n",
      "[14] : train loss 0.002034, val loss drop 0.0042 to 0.0023\n",
      "[15] : train loss 0.001702, val loss drop 0.0023 to 0.0021\n",
      "[28] : train loss 0.002013, val loss drop 0.0021 to 0.0014\n",
      "[29] : train loss 0.001078, val loss drop 0.0014 to 0.0011\n",
      "[32] : train loss 0.001557, val loss drop 0.0011 to 0.0009\n",
      "[57] : train loss 0.000427, val loss drop 0.0009 to 0.0006\n",
      "[67] : train loss 0.000602, val loss drop 0.0006 to 0.0004\n",
      "fold 8\n",
      "[1] : train loss 2.592550, val loss drop 10000000.0000 to 1.2194\n",
      "[2] : train loss 0.622185, val loss drop 1.2194 to 0.2225\n",
      "[3] : train loss 0.122775, val loss drop 0.2225 to 0.1977\n",
      "[4] : train loss 0.040786, val loss drop 0.1977 to 0.0335\n",
      "[5] : train loss 0.019830, val loss drop 0.0335 to 0.0146\n",
      "[6] : train loss 0.009600, val loss drop 0.0146 to 0.0085\n",
      "[7] : train loss 0.005388, val loss drop 0.0085 to 0.0060\n",
      "[8] : train loss 0.003566, val loss drop 0.0060 to 0.0056\n",
      "[9] : train loss 0.003002, val loss drop 0.0056 to 0.0055\n",
      "[10] : train loss 0.002367, val loss drop 0.0055 to 0.0029\n",
      "[12] : train loss 0.001662, val loss drop 0.0029 to 0.0025\n",
      "[14] : train loss 0.002022, val loss drop 0.0025 to 0.0017\n",
      "[22] : train loss 0.001445, val loss drop 0.0017 to 0.0015\n",
      "[23] : train loss 0.001486, val loss drop 0.0015 to 0.0011\n",
      "[36] : train loss 0.000858, val loss drop 0.0011 to 0.0008\n",
      "[38] : train loss 0.000416, val loss drop 0.0008 to 0.0007\n",
      "[40] : train loss 0.000413, val loss drop 0.0007 to 0.0007\n",
      "[53] : train loss 0.000616, val loss drop 0.0007 to 0.0006\n",
      "[80] : train loss 0.000791, val loss drop 0.0006 to 0.0005\n",
      "fold 9\n",
      "[1] : train loss 2.408671, val loss drop 10000000.0000 to 1.4047\n",
      "[2] : train loss 0.728693, val loss drop 1.4047 to 0.2685\n",
      "[3] : train loss 0.144415, val loss drop 0.2685 to 0.0671\n",
      "[4] : train loss 0.048580, val loss drop 0.0671 to 0.0355\n",
      "[5] : train loss 0.021660, val loss drop 0.0355 to 0.0316\n",
      "[6] : train loss 0.013435, val loss drop 0.0316 to 0.0189\n",
      "[7] : train loss 0.009386, val loss drop 0.0189 to 0.0110\n",
      "[8] : train loss 0.005537, val loss drop 0.0110 to 0.0065\n",
      "[9] : train loss 0.003377, val loss drop 0.0065 to 0.0044\n",
      "[10] : train loss 0.002535, val loss drop 0.0044 to 0.0039\n",
      "[11] : train loss 0.003233, val loss drop 0.0039 to 0.0036\n",
      "[13] : train loss 0.001858, val loss drop 0.0036 to 0.0027\n",
      "[15] : train loss 0.001708, val loss drop 0.0027 to 0.0023\n",
      "[16] : train loss 0.001791, val loss drop 0.0023 to 0.0017\n",
      "[25] : train loss 0.000989, val loss drop 0.0017 to 0.0015\n",
      "[31] : train loss 0.001448, val loss drop 0.0015 to 0.0014\n",
      "[32] : train loss 0.000783, val loss drop 0.0014 to 0.0010\n",
      "[35] : train loss 0.000737, val loss drop 0.0010 to 0.0007\n",
      "[37] : train loss 0.000480, val loss drop 0.0007 to 0.0007\n",
      "[39] : train loss 0.000707, val loss drop 0.0007 to 0.0006\n",
      "[57] : train loss 0.000692, val loss drop 0.0006 to 0.0004\n",
      "[84] : train loss 0.000276, val loss drop 0.0004 to 0.0003\n",
      "fold 10\n",
      "[1] : train loss 2.715734, val loss drop 10000000.0000 to 1.9593\n",
      "[2] : train loss 1.084592, val loss drop 1.9593 to 0.4797\n",
      "[3] : train loss 0.236315, val loss drop 0.4797 to 0.1746\n",
      "[4] : train loss 0.067132, val loss drop 0.1746 to 0.0525\n",
      "[5] : train loss 0.027473, val loss drop 0.0525 to 0.0244\n",
      "[7] : train loss 0.008490, val loss drop 0.0244 to 0.0173\n",
      "[8] : train loss 0.005422, val loss drop 0.0173 to 0.0049\n",
      "[10] : train loss 0.002435, val loss drop 0.0049 to 0.0034\n",
      "[13] : train loss 0.001488, val loss drop 0.0034 to 0.0021\n",
      "[15] : train loss 0.001146, val loss drop 0.0021 to 0.0021\n",
      "[17] : train loss 0.001081, val loss drop 0.0021 to 0.0018\n",
      "[18] : train loss 0.001197, val loss drop 0.0018 to 0.0014\n",
      "[23] : train loss 0.001121, val loss drop 0.0014 to 0.0012\n",
      "[26] : train loss 0.000907, val loss drop 0.0012 to 0.0011\n",
      "[32] : train loss 0.000657, val loss drop 0.0011 to 0.0007\n",
      "[51] : train loss 0.000497, val loss drop 0.0007 to 0.0005\n",
      "[66] : train loss 0.000733, val loss drop 0.0005 to 0.0005\n",
      "[77] : train loss 0.000393, val loss drop 0.0005 to 0.0004\n",
      "M train...\n",
      "fold 1\n",
      "[1] : train loss 44.181772, val loss drop 10000000.0000 to 5.3709\n",
      "[3] : train loss 1.552632, val loss drop 5.3709 to 4.1246\n",
      "[4] : train loss 0.834408, val loss drop 4.1246 to 3.1873\n",
      "[5] : train loss 0.473481, val loss drop 3.1873 to 0.5738\n",
      "[6] : train loss 0.320176, val loss drop 0.5738 to 0.2406\n",
      "[9] : train loss 0.396400, val loss drop 0.2406 to 0.2274\n",
      "[13] : train loss 0.241500, val loss drop 0.2274 to 0.0781\n",
      "[14] : train loss 0.303777, val loss drop 0.0781 to 0.0618\n",
      "[31] : train loss 0.160864, val loss drop 0.0618 to 0.0545\n",
      "[48] : train loss 0.112577, val loss drop 0.0545 to 0.0344\n",
      "[62] : train loss 0.097592, val loss drop 0.0344 to 0.0284\n",
      "[90] : train loss 0.106015, val loss drop 0.0284 to 0.0276\n",
      "[91] : train loss 0.088146, val loss drop 0.0276 to 0.0198\n",
      "fold 2\n",
      "[1] : train loss 40.630521, val loss drop 10000000.0000 to 21.2723\n",
      "[2] : train loss 4.704691, val loss drop 21.2723 to 18.1748\n",
      "[3] : train loss 1.629234, val loss drop 18.1748 to 2.8480\n",
      "[4] : train loss 0.762005, val loss drop 2.8480 to 0.9112\n",
      "[5] : train loss 0.513295, val loss drop 0.9112 to 0.4559\n",
      "[6] : train loss 0.407752, val loss drop 0.4559 to 0.2601\n",
      "[8] : train loss 0.261182, val loss drop 0.2601 to 0.2141\n",
      "[14] : train loss 0.271819, val loss drop 0.2141 to 0.1082\n",
      "[21] : train loss 0.524004, val loss drop 0.1082 to 0.0654\n",
      "[24] : train loss 0.135186, val loss drop 0.0654 to 0.0559\n",
      "[26] : train loss 0.249042, val loss drop 0.0559 to 0.0439\n",
      "[36] : train loss 0.091070, val loss drop 0.0439 to 0.0281\n",
      "fold 3\n",
      "[1] : train loss 28.923153, val loss drop 10000000.0000 to 47.0861\n",
      "[2] : train loss 3.077961, val loss drop 47.0861 to 1.0348\n",
      "[5] : train loss 0.426809, val loss drop 1.0348 to 0.6641\n",
      "[6] : train loss 0.530122, val loss drop 0.6641 to 0.3010\n",
      "[8] : train loss 0.259584, val loss drop 0.3010 to 0.2886\n",
      "[9] : train loss 0.177794, val loss drop 0.2886 to 0.0859\n",
      "[20] : train loss 0.206010, val loss drop 0.0859 to 0.0606\n",
      "[22] : train loss 0.275350, val loss drop 0.0606 to 0.0396\n",
      "[25] : train loss 0.220836, val loss drop 0.0396 to 0.0359\n",
      "[46] : train loss 0.369041, val loss drop 0.0359 to 0.0341\n",
      "[63] : train loss 0.098398, val loss drop 0.0341 to 0.0296\n",
      "[67] : train loss 0.097073, val loss drop 0.0296 to 0.0287\n",
      "[78] : train loss 0.074539, val loss drop 0.0287 to 0.0276\n",
      "[81] : train loss 0.193952, val loss drop 0.0276 to 0.0261\n",
      "fold 4\n",
      "[1] : train loss 35.418331, val loss drop 10000000.0000 to 63.3064\n",
      "[2] : train loss 4.269515, val loss drop 63.3064 to 1.8430\n",
      "[4] : train loss 0.802407, val loss drop 1.8430 to 0.8583\n",
      "[5] : train loss 0.663514, val loss drop 0.8583 to 0.2942\n",
      "[10] : train loss 0.520033, val loss drop 0.2942 to 0.2052\n",
      "[11] : train loss 0.468903, val loss drop 0.2052 to 0.1950\n",
      "[12] : train loss 0.285730, val loss drop 0.1950 to 0.1431\n",
      "[18] : train loss 0.404633, val loss drop 0.1431 to 0.1390\n",
      "[20] : train loss 0.172979, val loss drop 0.1390 to 0.0989\n",
      "[25] : train loss 0.191789, val loss drop 0.0989 to 0.0585\n",
      "[26] : train loss 0.200586, val loss drop 0.0585 to 0.0552\n",
      "[35] : train loss 0.273634, val loss drop 0.0552 to 0.0347\n",
      "[55] : train loss 0.137295, val loss drop 0.0347 to 0.0201\n",
      "fold 5\n",
      "[1] : train loss 30.066747, val loss drop 10000000.0000 to 31.2150\n",
      "[2] : train loss 3.072328, val loss drop 31.2150 to 1.8725\n",
      "[3] : train loss 1.202996, val loss drop 1.8725 to 1.5634\n",
      "[4] : train loss 0.871506, val loss drop 1.5634 to 1.3134\n",
      "[5] : train loss 0.628085, val loss drop 1.3134 to 1.0648\n",
      "[6] : train loss 0.380411, val loss drop 1.0648 to 0.2919\n",
      "[8] : train loss 0.323461, val loss drop 0.2919 to 0.1932\n",
      "[9] : train loss 0.331512, val loss drop 0.1932 to 0.1009\n",
      "[11] : train loss 0.329727, val loss drop 0.1009 to 0.0774\n",
      "[15] : train loss 0.308103, val loss drop 0.0774 to 0.0570\n",
      "[30] : train loss 0.303060, val loss drop 0.0570 to 0.0459\n",
      "[41] : train loss 0.075805, val loss drop 0.0459 to 0.0236\n",
      "[51] : train loss 0.116224, val loss drop 0.0236 to 0.0224\n",
      "[80] : train loss 0.116290, val loss drop 0.0224 to 0.0185\n",
      "fold 6\n",
      "[1] : train loss 28.036482, val loss drop 10000000.0000 to 49.1208\n",
      "[2] : train loss 3.215703, val loss drop 49.1208 to 4.8694\n",
      "[3] : train loss 0.963861, val loss drop 4.8694 to 1.6139\n",
      "[4] : train loss 0.738315, val loss drop 1.6139 to 0.4486\n",
      "[5] : train loss 0.428728, val loss drop 0.4486 to 0.2871\n",
      "[6] : train loss 0.400880, val loss drop 0.2871 to 0.2112\n",
      "[12] : train loss 0.657324, val loss drop 0.2112 to 0.0816\n",
      "[17] : train loss 0.397278, val loss drop 0.0816 to 0.0673\n",
      "[34] : train loss 0.101306, val loss drop 0.0673 to 0.0651\n",
      "[42] : train loss 0.572779, val loss drop 0.0651 to 0.0582\n",
      "[52] : train loss 0.205621, val loss drop 0.0582 to 0.0282\n",
      "[64] : train loss 0.096575, val loss drop 0.0282 to 0.0210\n",
      "[80] : train loss 0.108178, val loss drop 0.0210 to 0.0195\n",
      "fold 7\n",
      "[1] : train loss 38.749172, val loss drop 10000000.0000 to 16.6467\n",
      "[2] : train loss 4.263310, val loss drop 16.6467 to 12.4090\n",
      "[3] : train loss 1.588869, val loss drop 12.4090 to 11.7161\n",
      "[4] : train loss 0.861995, val loss drop 11.7161 to 5.1504\n",
      "[5] : train loss 0.531617, val loss drop 5.1504 to 1.3258\n",
      "[6] : train loss 0.417168, val loss drop 1.3258 to 1.2306\n",
      "[7] : train loss 0.431726, val loss drop 1.2306 to 0.7444\n",
      "[8] : train loss 0.510215, val loss drop 0.7444 to 0.6046\n",
      "[9] : train loss 0.279976, val loss drop 0.6046 to 0.1653\n",
      "[15] : train loss 0.293703, val loss drop 0.1653 to 0.0757\n",
      "[21] : train loss 0.227106, val loss drop 0.0757 to 0.0549\n",
      "[24] : train loss 0.262173, val loss drop 0.0549 to 0.0421\n",
      "[29] : train loss 0.273849, val loss drop 0.0421 to 0.0336\n",
      "[32] : train loss 0.124465, val loss drop 0.0336 to 0.0253\n",
      "[96] : train loss 0.206064, val loss drop 0.0253 to 0.0220\n",
      "[98] : train loss 0.174283, val loss drop 0.0220 to 0.0121\n",
      "fold 8\n",
      "[1] : train loss 26.736944, val loss drop 10000000.0000 to 71.1200\n",
      "[2] : train loss 2.621892, val loss drop 71.1200 to 2.3778\n",
      "[3] : train loss 0.960774, val loss drop 2.3778 to 0.7005\n",
      "[5] : train loss 0.397699, val loss drop 0.7005 to 0.3564\n",
      "[6] : train loss 0.417950, val loss drop 0.3564 to 0.3080\n",
      "[7] : train loss 0.460639, val loss drop 0.3080 to 0.1160\n",
      "[9] : train loss 0.188508, val loss drop 0.1160 to 0.1084\n",
      "[11] : train loss 0.399083, val loss drop 0.1084 to 0.0689\n",
      "[32] : train loss 0.257656, val loss drop 0.0689 to 0.0515\n",
      "[35] : train loss 0.095402, val loss drop 0.0515 to 0.0442\n",
      "[42] : train loss 0.177741, val loss drop 0.0442 to 0.0251\n",
      "fold 9\n",
      "[1] : train loss 35.064094, val loss drop 10000000.0000 to 50.1096\n",
      "[2] : train loss 3.210118, val loss drop 50.1096 to 10.7565\n",
      "[3] : train loss 1.765701, val loss drop 10.7565 to 4.4581\n",
      "[4] : train loss 0.746986, val loss drop 4.4581 to 0.8092\n",
      "[5] : train loss 0.511643, val loss drop 0.8092 to 0.2899\n",
      "[6] : train loss 0.314805, val loss drop 0.2899 to 0.1650\n",
      "[8] : train loss 0.253415, val loss drop 0.1650 to 0.1046\n",
      "[13] : train loss 0.264859, val loss drop 0.1046 to 0.0659\n",
      "[20] : train loss 0.207833, val loss drop 0.0659 to 0.0652\n",
      "[22] : train loss 0.119324, val loss drop 0.0652 to 0.0390\n",
      "[31] : train loss 0.072857, val loss drop 0.0390 to 0.0173\n",
      "[72] : train loss 0.061987, val loss drop 0.0173 to 0.0150\n",
      "fold 10\n",
      "[1] : train loss 34.706306, val loss drop 10000000.0000 to 96.9231\n",
      "[2] : train loss 4.062707, val loss drop 96.9231 to 9.0471\n",
      "[3] : train loss 1.871076, val loss drop 9.0471 to 2.6313\n",
      "[4] : train loss 0.912406, val loss drop 2.6313 to 0.5436\n",
      "[5] : train loss 0.636259, val loss drop 0.5436 to 0.2547\n",
      "[7] : train loss 0.218934, val loss drop 0.2547 to 0.1716\n",
      "[8] : train loss 0.285789, val loss drop 0.1716 to 0.1663\n",
      "[9] : train loss 0.390933, val loss drop 0.1663 to 0.0863\n",
      "[10] : train loss 0.156033, val loss drop 0.0863 to 0.0564\n",
      "[17] : train loss 0.303763, val loss drop 0.0564 to 0.0535\n",
      "[48] : train loss 0.238546, val loss drop 0.0535 to 0.0479\n",
      "[49] : train loss 0.256859, val loss drop 0.0479 to 0.0447\n",
      "[57] : train loss 0.205394, val loss drop 0.0447 to 0.0321\n",
      "[59] : train loss 0.140409, val loss drop 0.0321 to 0.0160\n",
      "[61] : train loss 0.128387, val loss drop 0.0160 to 0.0135\n",
      "V train...\n",
      "fold 1\n",
      "[1] : train loss 43.481695, val loss drop 10000000.0000 to 3.0936\n",
      "[2] : train loss 0.900521, val loss drop 3.0936 to 0.4138\n",
      "[3] : train loss 0.285779, val loss drop 0.4138 to 0.3613\n",
      "[4] : train loss 0.188053, val loss drop 0.3613 to 0.1289\n",
      "[5] : train loss 0.089446, val loss drop 0.1289 to 0.0942\n",
      "[7] : train loss 0.149799, val loss drop 0.0942 to 0.0678\n",
      "[10] : train loss 0.046554, val loss drop 0.0678 to 0.0622\n",
      "[14] : train loss 0.041399, val loss drop 0.0622 to 0.0355\n",
      "[24] : train loss 0.052698, val loss drop 0.0355 to 0.0263\n",
      "[32] : train loss 0.027001, val loss drop 0.0263 to 0.0170\n",
      "[42] : train loss 0.009706, val loss drop 0.0170 to 0.0169\n",
      "[44] : train loss 0.029338, val loss drop 0.0169 to 0.0140\n",
      "[58] : train loss 0.018610, val loss drop 0.0140 to 0.0096\n",
      "[85] : train loss 0.010342, val loss drop 0.0096 to 0.0084\n",
      "[98] : train loss 0.010244, val loss drop 0.0084 to 0.0081\n",
      "fold 2\n",
      "[1] : train loss 5.588266, val loss drop 10000000.0000 to 0.9350\n",
      "[2] : train loss 0.276621, val loss drop 0.9350 to 0.1560\n",
      "[3] : train loss 0.100569, val loss drop 0.1560 to 0.0585\n",
      "[4] : train loss 0.049981, val loss drop 0.0585 to 0.0397\n",
      "[5] : train loss 0.026806, val loss drop 0.0397 to 0.0216\n",
      "[7] : train loss 0.016580, val loss drop 0.0216 to 0.0158\n",
      "[9] : train loss 0.015523, val loss drop 0.0158 to 0.0143\n",
      "[11] : train loss 0.014787, val loss drop 0.0143 to 0.0108\n",
      "[12] : train loss 0.007413, val loss drop 0.0108 to 0.0108\n",
      "[13] : train loss 0.006131, val loss drop 0.0108 to 0.0104\n",
      "[14] : train loss 0.005604, val loss drop 0.0104 to 0.0078\n",
      "[15] : train loss 0.004733, val loss drop 0.0078 to 0.0060\n",
      "[21] : train loss 0.003576, val loss drop 0.0060 to 0.0051\n",
      "[32] : train loss 0.006500, val loss drop 0.0051 to 0.0035\n",
      "[52] : train loss 0.004399, val loss drop 0.0035 to 0.0027\n",
      "[63] : train loss 0.002579, val loss drop 0.0027 to 0.0025\n",
      "[68] : train loss 0.001954, val loss drop 0.0025 to 0.0021\n",
      "[71] : train loss 0.002369, val loss drop 0.0021 to 0.0021\n",
      "[88] : train loss 0.003767, val loss drop 0.0021 to 0.0019\n",
      "fold 3\n",
      "[1] : train loss 82.034731, val loss drop 10000000.0000 to 1.4751\n",
      "[2] : train loss 0.684765, val loss drop 1.4751 to 1.2403\n",
      "[3] : train loss 0.262360, val loss drop 1.2403 to 0.5009\n",
      "[4] : train loss 0.144223, val loss drop 0.5009 to 0.1637\n",
      "[5] : train loss 0.084583, val loss drop 0.1637 to 0.0784\n",
      "[6] : train loss 0.058578, val loss drop 0.0784 to 0.0526\n",
      "[7] : train loss 0.045288, val loss drop 0.0526 to 0.0464\n",
      "[8] : train loss 0.034833, val loss drop 0.0464 to 0.0430\n",
      "[9] : train loss 0.031177, val loss drop 0.0430 to 0.0353\n",
      "[11] : train loss 0.026129, val loss drop 0.0353 to 0.0339\n",
      "[12] : train loss 0.020773, val loss drop 0.0339 to 0.0288\n",
      "[13] : train loss 0.021405, val loss drop 0.0288 to 0.0259\n",
      "[15] : train loss 0.015869, val loss drop 0.0259 to 0.0183\n",
      "[25] : train loss 0.011403, val loss drop 0.0183 to 0.0179\n",
      "[29] : train loss 0.013847, val loss drop 0.0179 to 0.0138\n",
      "[36] : train loss 0.008478, val loss drop 0.0138 to 0.0127\n",
      "[44] : train loss 0.012141, val loss drop 0.0127 to 0.0119\n",
      "[57] : train loss 0.004162, val loss drop 0.0119 to 0.0095\n",
      "[58] : train loss 0.004456, val loss drop 0.0095 to 0.0091\n",
      "[69] : train loss 0.006443, val loss drop 0.0091 to 0.0075\n",
      "[88] : train loss 0.003744, val loss drop 0.0075 to 0.0070\n",
      "fold 4\n",
      "[1] : train loss 38.494880, val loss drop 10000000.0000 to 0.2328\n",
      "[2] : train loss 0.114561, val loss drop 0.2328 to 0.0862\n",
      "[3] : train loss 0.053860, val loss drop 0.0862 to 0.0542\n",
      "[4] : train loss 0.027737, val loss drop 0.0542 to 0.0170\n",
      "[5] : train loss 0.020487, val loss drop 0.0170 to 0.0127\n",
      "[6] : train loss 0.021678, val loss drop 0.0127 to 0.0113\n",
      "[7] : train loss 0.018918, val loss drop 0.0113 to 0.0081\n",
      "[13] : train loss 0.006553, val loss drop 0.0081 to 0.0058\n",
      "[15] : train loss 0.005696, val loss drop 0.0058 to 0.0057\n",
      "[22] : train loss 0.009351, val loss drop 0.0057 to 0.0047\n",
      "[25] : train loss 0.003808, val loss drop 0.0047 to 0.0039\n",
      "[37] : train loss 0.008175, val loss drop 0.0039 to 0.0029\n",
      "[41] : train loss 0.002887, val loss drop 0.0029 to 0.0023\n",
      "[55] : train loss 0.002052, val loss drop 0.0023 to 0.0020\n",
      "[57] : train loss 0.002218, val loss drop 0.0020 to 0.0019\n",
      "[73] : train loss 0.001758, val loss drop 0.0019 to 0.0016\n",
      "[96] : train loss 0.002378, val loss drop 0.0016 to 0.0015\n",
      "[100] : train loss 0.001062, val loss drop 0.0015 to 0.0015\n",
      "fold 5\n",
      "[1] : train loss 14.192998, val loss drop 10000000.0000 to 5.4806\n",
      "[2] : train loss 0.886351, val loss drop 5.4806 to 0.2534\n",
      "[4] : train loss 0.120591, val loss drop 0.2534 to 0.1032\n",
      "[5] : train loss 0.062561, val loss drop 0.1032 to 0.0401\n",
      "[6] : train loss 0.033467, val loss drop 0.0401 to 0.0292\n",
      "[7] : train loss 0.024358, val loss drop 0.0292 to 0.0213\n",
      "[9] : train loss 0.017501, val loss drop 0.0213 to 0.0172\n",
      "[10] : train loss 0.013916, val loss drop 0.0172 to 0.0145\n",
      "[15] : train loss 0.008328, val loss drop 0.0145 to 0.0125\n",
      "[19] : train loss 0.005797, val loss drop 0.0125 to 0.0091\n",
      "[25] : train loss 0.006438, val loss drop 0.0091 to 0.0084\n",
      "[30] : train loss 0.006173, val loss drop 0.0084 to 0.0072\n",
      "[33] : train loss 0.005908, val loss drop 0.0072 to 0.0061\n",
      "[35] : train loss 0.005186, val loss drop 0.0061 to 0.0060\n",
      "[52] : train loss 0.005777, val loss drop 0.0060 to 0.0058\n",
      "[61] : train loss 0.013662, val loss drop 0.0058 to 0.0045\n",
      "[66] : train loss 0.002051, val loss drop 0.0045 to 0.0044\n",
      "[71] : train loss 0.004804, val loss drop 0.0044 to 0.0037\n",
      "[82] : train loss 0.001852, val loss drop 0.0037 to 0.0032\n",
      "[96] : train loss 0.009775, val loss drop 0.0032 to 0.0029\n",
      "fold 6\n",
      "[1] : train loss 24.668329, val loss drop 10000000.0000 to 0.9870\n",
      "[2] : train loss 0.331391, val loss drop 0.9870 to 0.3981\n",
      "[3] : train loss 0.141013, val loss drop 0.3981 to 0.1077\n",
      "[4] : train loss 0.084793, val loss drop 0.1077 to 0.0690\n",
      "[5] : train loss 0.050971, val loss drop 0.0690 to 0.0561\n",
      "[6] : train loss 0.058558, val loss drop 0.0561 to 0.0466\n",
      "[7] : train loss 0.029484, val loss drop 0.0466 to 0.0403\n",
      "[12] : train loss 0.023032, val loss drop 0.0403 to 0.0372\n",
      "[13] : train loss 0.019339, val loss drop 0.0372 to 0.0302\n",
      "[14] : train loss 0.016566, val loss drop 0.0302 to 0.0282\n",
      "[19] : train loss 0.024931, val loss drop 0.0282 to 0.0169\n",
      "[27] : train loss 0.055882, val loss drop 0.0169 to 0.0142\n",
      "[33] : train loss 0.007467, val loss drop 0.0142 to 0.0121\n",
      "[37] : train loss 0.004292, val loss drop 0.0121 to 0.0095\n",
      "[38] : train loss 0.004827, val loss drop 0.0095 to 0.0092\n",
      "[45] : train loss 0.003773, val loss drop 0.0092 to 0.0078\n",
      "[51] : train loss 0.002650, val loss drop 0.0078 to 0.0073\n",
      "[55] : train loss 0.003231, val loss drop 0.0073 to 0.0072\n",
      "[65] : train loss 0.005044, val loss drop 0.0072 to 0.0071\n",
      "[73] : train loss 0.003756, val loss drop 0.0071 to 0.0069\n",
      "[74] : train loss 0.004354, val loss drop 0.0069 to 0.0067\n",
      "[75] : train loss 0.003715, val loss drop 0.0067 to 0.0065\n",
      "[77] : train loss 0.002057, val loss drop 0.0065 to 0.0057\n",
      "fold 7\n",
      "[1] : train loss 7.420454, val loss drop 10000000.0000 to 0.6448\n",
      "[2] : train loss 0.241899, val loss drop 0.6448 to 0.1332\n",
      "[3] : train loss 0.082661, val loss drop 0.1332 to 0.0977\n",
      "[4] : train loss 0.043754, val loss drop 0.0977 to 0.0221\n",
      "[6] : train loss 0.013932, val loss drop 0.0221 to 0.0169\n",
      "[7] : train loss 0.011653, val loss drop 0.0169 to 0.0168\n",
      "[8] : train loss 0.008092, val loss drop 0.0168 to 0.0149\n",
      "[9] : train loss 0.007307, val loss drop 0.0149 to 0.0119\n",
      "[13] : train loss 0.010250, val loss drop 0.0119 to 0.0092\n",
      "[17] : train loss 0.006787, val loss drop 0.0092 to 0.0088\n",
      "[18] : train loss 0.005054, val loss drop 0.0088 to 0.0079\n",
      "[23] : train loss 0.004372, val loss drop 0.0079 to 0.0054\n",
      "[33] : train loss 0.007615, val loss drop 0.0054 to 0.0051\n",
      "[36] : train loss 0.002394, val loss drop 0.0051 to 0.0047\n",
      "[39] : train loss 0.003443, val loss drop 0.0047 to 0.0040\n",
      "[44] : train loss 0.008407, val loss drop 0.0040 to 0.0034\n",
      "[71] : train loss 0.001496, val loss drop 0.0034 to 0.0029\n",
      "[78] : train loss 0.001641, val loss drop 0.0029 to 0.0028\n",
      "[82] : train loss 0.003560, val loss drop 0.0028 to 0.0028\n",
      "[83] : train loss 0.001561, val loss drop 0.0028 to 0.0024\n",
      "[84] : train loss 0.003773, val loss drop 0.0024 to 0.0024\n",
      "[90] : train loss 0.003012, val loss drop 0.0024 to 0.0022\n",
      "[91] : train loss 0.003014, val loss drop 0.0022 to 0.0020\n",
      "fold 8\n",
      "[1] : train loss 13.128806, val loss drop 10000000.0000 to 2.7705\n",
      "[2] : train loss 0.904818, val loss drop 2.7705 to 0.4768\n",
      "[3] : train loss 0.289670, val loss drop 0.4768 to 0.1445\n",
      "[4] : train loss 0.159767, val loss drop 0.1445 to 0.1178\n",
      "[5] : train loss 0.073044, val loss drop 0.1178 to 0.0557\n",
      "[6] : train loss 0.044567, val loss drop 0.0557 to 0.0505\n",
      "[7] : train loss 0.036070, val loss drop 0.0505 to 0.0441\n",
      "[8] : train loss 0.027418, val loss drop 0.0441 to 0.0433\n",
      "[9] : train loss 0.024629, val loss drop 0.0433 to 0.0299\n",
      "[10] : train loss 0.017777, val loss drop 0.0299 to 0.0231\n",
      "[15] : train loss 0.011934, val loss drop 0.0231 to 0.0200\n",
      "[18] : train loss 0.017058, val loss drop 0.0200 to 0.0191\n",
      "[21] : train loss 0.020795, val loss drop 0.0191 to 0.0134\n",
      "[26] : train loss 0.022415, val loss drop 0.0134 to 0.0131\n",
      "[46] : train loss 0.007863, val loss drop 0.0131 to 0.0096\n",
      "[49] : train loss 0.010322, val loss drop 0.0096 to 0.0083\n",
      "[52] : train loss 0.005654, val loss drop 0.0083 to 0.0070\n",
      "[68] : train loss 0.005071, val loss drop 0.0070 to 0.0066\n",
      "[73] : train loss 0.007685, val loss drop 0.0066 to 0.0058\n",
      "[95] : train loss 0.011007, val loss drop 0.0058 to 0.0057\n",
      "[97] : train loss 0.004432, val loss drop 0.0057 to 0.0052\n",
      "fold 9\n",
      "[1] : train loss 76.215744, val loss drop 10000000.0000 to 0.3154\n",
      "[3] : train loss 0.135242, val loss drop 0.3154 to 0.1195\n",
      "[4] : train loss 0.069741, val loss drop 0.1195 to 0.0685\n",
      "[5] : train loss 0.049303, val loss drop 0.0685 to 0.0467\n",
      "[6] : train loss 0.031388, val loss drop 0.0467 to 0.0336\n",
      "[7] : train loss 0.025258, val loss drop 0.0336 to 0.0301\n",
      "[8] : train loss 0.021473, val loss drop 0.0301 to 0.0253\n",
      "[9] : train loss 0.019429, val loss drop 0.0253 to 0.0242\n",
      "[10] : train loss 0.014196, val loss drop 0.0242 to 0.0181\n",
      "[12] : train loss 0.012171, val loss drop 0.0181 to 0.0144\n",
      "[15] : train loss 0.012170, val loss drop 0.0144 to 0.0119\n",
      "[17] : train loss 0.006858, val loss drop 0.0119 to 0.0112\n",
      "[21] : train loss 0.008586, val loss drop 0.0112 to 0.0106\n",
      "[24] : train loss 0.005561, val loss drop 0.0106 to 0.0091\n",
      "[26] : train loss 0.004249, val loss drop 0.0091 to 0.0075\n",
      "[37] : train loss 0.004482, val loss drop 0.0075 to 0.0067\n",
      "[43] : train loss 0.004781, val loss drop 0.0067 to 0.0066\n",
      "[47] : train loss 0.003246, val loss drop 0.0066 to 0.0052\n",
      "[63] : train loss 0.004770, val loss drop 0.0052 to 0.0048\n",
      "[71] : train loss 0.002632, val loss drop 0.0048 to 0.0043\n",
      "[85] : train loss 0.002561, val loss drop 0.0043 to 0.0038\n",
      "fold 10\n",
      "[1] : train loss 15.619650, val loss drop 10000000.0000 to 1.7037\n",
      "[2] : train loss 1.144232, val loss drop 1.7037 to 0.7801\n",
      "[3] : train loss 0.360802, val loss drop 0.7801 to 0.4366\n",
      "[4] : train loss 0.199265, val loss drop 0.4366 to 0.1056\n",
      "[5] : train loss 0.089834, val loss drop 0.1056 to 0.0685\n",
      "[7] : train loss 0.049494, val loss drop 0.0685 to 0.0348\n",
      "[10] : train loss 0.029325, val loss drop 0.0348 to 0.0317\n",
      "[17] : train loss 0.037592, val loss drop 0.0317 to 0.0197\n",
      "[19] : train loss 0.014509, val loss drop 0.0197 to 0.0160\n",
      "[23] : train loss 0.008908, val loss drop 0.0160 to 0.0126\n",
      "[39] : train loss 0.013026, val loss drop 0.0126 to 0.0108\n",
      "[40] : train loss 0.008014, val loss drop 0.0108 to 0.0104\n",
      "[41] : train loss 0.005020, val loss drop 0.0104 to 0.0091\n",
      "[43] : train loss 0.005427, val loss drop 0.0091 to 0.0081\n",
      "[50] : train loss 0.004259, val loss drop 0.0081 to 0.0074\n",
      "[52] : train loss 0.002907, val loss drop 0.0074 to 0.0059\n",
      "[85] : train loss 0.003607, val loss drop 0.0059 to 0.0052\n",
      "[91] : train loss 0.003729, val loss drop 0.0052 to 0.0050\n",
      "[92] : train loss 0.002533, val loss drop 0.0050 to 0.0043\n"
     ]
    }
   ],
   "source": [
    "loss_per_model = {}\n",
    "for name in ['XY','M','V']:\n",
    "    print('{} train...'.format(name))\n",
    "    \n",
    "    # make dataset\n",
    "    train_target = train_t[list(name)].values#.astype(np.float32)\n",
    "\n",
    "    # trainx, valx, trainy, valy = train_test_split(train_f, train_target, test_size = 0.2, shuffle = True, random_state = 38)\n",
    "    fold = KFold(nfold, shuffle = True, random_state= 25)\n",
    "    loss_per_cv = []\n",
    "    for i, (train_idx, val_idx) in enumerate(fold.split(train_f, y = train_target)):\n",
    "        print('fold {}'.format(i+1))\n",
    "        trainx = train_f[train_idx]\n",
    "        valx = train_f[val_idx]\n",
    "        trainy = train_target[train_idx]\n",
    "        valy = train_target[val_idx]\n",
    "        \n",
    "        train_dataset = dfDataset(trainx.astype(np.float32), trainy)\n",
    "        train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "        val_dataset = dfDataset(valx.astype(np.float32), valy)\n",
    "        val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "        fc = classifier([128, 64, 32, 16], input_size = 512*3*5, output_size = len(name))\n",
    "        conv = conv_block([16, 32, 64, 128, 256, 512], [1, 375, 5], (3, 1))\n",
    "\n",
    "        # define model\n",
    "        model = cnn_model(conv, fc)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = base_lr)\n",
    "\n",
    "        if name == 'XY':\n",
    "            criterion = E1_loss\n",
    "        else:\n",
    "            criterion = E2_loss\n",
    "\n",
    "        model = model.cuda()\n",
    "        if initialize:\n",
    "            model.apply(weights_init)\n",
    "\n",
    "        curr_loss = 1e+7\n",
    "        os.makedirs(save_path) if not os.path.exists(save_path) else None\n",
    "        #train\n",
    "        for ep in range(1, EPOCH + 1):\n",
    "            model.train()\n",
    "            loss = train_model(model, train_loader, criterion, optimizer, criterion)\n",
    "            model.eval()\n",
    "            val_loss =eval_model(model, val_loader, criterion)\n",
    "            if curr_loss > val_loss:\n",
    "                print('[{}] : train loss {:4f}, val loss drop {:.4f} to {:.4f}'.format(ep, np.mean(loss), curr_loss, val_loss))\n",
    "                curr_loss = val_loss\n",
    "                torch.save(model.state_dict(), os.path.join(save_path, 'model_{}_fold{}.pt'.format(name, i+1)))\n",
    "        loss_per_cv.append(curr_loss)\n",
    "    loss_per_model[name] = loss_per_cv           \n",
    "            #else:\n",
    "                #print('[{}] : train loss {:.4f}, val loss {:.4f}, not drop'.format(ep, np.mean(loss), val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_path, 'loss_info.json'), 'w') as f:\n",
    "    for k in loss_per_model:\n",
    "        loss_per_model[k] = np.mean(loss_per_model[k])\n",
    "    f.write(json.dumps(loss_per_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(os.path.join(root_dir, 'sample_submission.csv'))\n",
    "for name in ['XY','M','V']:\n",
    "    fc = classifier([128, 64, 32, 16], input_size = 512*3*5, output_size = len(name))\n",
    "    conv = conv_block([16, 32, 64, 128, 256, 512], [1, 375, 5], (3, 1))\n",
    "    # define model\n",
    "    model = cnn_model(conv, fc)\n",
    "    pred_array = []\n",
    "    for i in range(1, nfold + 1):\n",
    "        model.load_state_dict(torch.load(os.path.join(save_path, 'model_{}_fold{}.pt'.format(name, i))))\n",
    "        model = model.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predict = model(test_f.cuda())\n",
    "        pred_array.append(predict.detach().cpu().numpy())\n",
    "    submission[list(name)] = np.mean(pred_array, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>M</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2800</td>\n",
       "      <td>-261.139008</td>\n",
       "      <td>-39.881229</td>\n",
       "      <td>111.966736</td>\n",
       "      <td>0.434986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2801</td>\n",
       "      <td>316.171234</td>\n",
       "      <td>-286.514954</td>\n",
       "      <td>90.317627</td>\n",
       "      <td>0.421709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2802</td>\n",
       "      <td>-233.366653</td>\n",
       "      <td>128.657593</td>\n",
       "      <td>28.895294</td>\n",
       "      <td>0.357899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2803</td>\n",
       "      <td>160.693039</td>\n",
       "      <td>276.158539</td>\n",
       "      <td>27.653961</td>\n",
       "      <td>0.372838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2804</td>\n",
       "      <td>-170.325470</td>\n",
       "      <td>187.950928</td>\n",
       "      <td>133.650543</td>\n",
       "      <td>0.478190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id           X           Y           M         V\n",
       "0  2800 -261.139008  -39.881229  111.966736  0.434986\n",
       "1  2801  316.171234 -286.514954   90.317627  0.421709\n",
       "2  2802 -233.366653  128.657593   28.895294  0.357899\n",
       "3  2803  160.693039  276.158539   27.653961  0.372838\n",
       "4  2804 -170.325470  187.950928  133.650543  0.478190"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(os.path.join(save_path, 'submit.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 10)\n",
    "y = torch.randn(1, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
