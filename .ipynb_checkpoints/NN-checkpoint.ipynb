{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import platform\n",
    "plt.style.use('seaborn')\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "from metric import E1_loss, E2_loss, total_loss\n",
    "from models import classifier, cnn_model, conv_block, cnn_parallel\n",
    "from utils import train_model, eval_model, dfDataset, weights_init\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 100\n",
    "base_lr = 0.001\n",
    "now = datetime.strftime(datetime.now(), '%Y%m%d-%H%M%S')\n",
    "save_path = './model/{}'.format(now)\n",
    "initialize = True\n",
    "print_summary = True\n",
    "batch_size = 256\n",
    "nfold = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == 'Windows':\n",
    "    root_dir = 'D:/datasets/KAERI_dataset/'\n",
    "else:\n",
    "    root_dir = '/home/bskim/project/kaeri/KAERI_dataset/'\n",
    "\n",
    "train_f = pd.read_csv(os.path.join(root_dir, 'train_features.csv'))\n",
    "train_t = pd.read_csv(os.path.join(root_dir, 'train_target.csv'))\n",
    "test_f = pd.read_csv(os.path.join(root_dir, 'test_features.csv'))\n",
    "\n",
    "train_f = train_f[['Time','S1','S2','S3','S4']].values\n",
    "train_f = train_f.reshape((-1, 1, 375, 5))#.astype(np.float32)\n",
    "\n",
    "test_f = test_f[['Time','S1','S2','S3','S4']].values\n",
    "test_f = test_f.reshape((-1, 1, 375, 5))#.astype(np.float32)\n",
    "test_f = torch.FloatTensor(test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XY train...\n",
      "fold 1\n",
      "[1] : train loss 2.973700, val loss drop 10000000.0000 to 2.2627\n",
      "[2] : train loss 1.824854, val loss drop 2.2627 to 0.8012\n",
      "[3] : train loss 0.496061, val loss drop 0.8012 to 0.3402\n",
      "[5] : train loss 0.024229, val loss drop 0.3402 to 0.1148\n",
      "[6] : train loss 0.010454, val loss drop 0.1148 to 0.0175\n",
      "[8] : train loss 0.005938, val loss drop 0.0175 to 0.0095\n",
      "[10] : train loss 0.004702, val loss drop 0.0095 to 0.0041\n",
      "[13] : train loss 0.002094, val loss drop 0.0041 to 0.0030\n",
      "[21] : train loss 0.002617, val loss drop 0.0030 to 0.0020\n",
      "[22] : train loss 0.002724, val loss drop 0.0020 to 0.0015\n",
      "[29] : train loss 0.002374, val loss drop 0.0015 to 0.0015\n",
      "[30] : train loss 0.001645, val loss drop 0.0015 to 0.0013\n",
      "[39] : train loss 0.000965, val loss drop 0.0013 to 0.0011\n",
      "[50] : train loss 0.001447, val loss drop 0.0011 to 0.0009\n",
      "[51] : train loss 0.000649, val loss drop 0.0009 to 0.0006\n",
      "[85] : train loss 0.000717, val loss drop 0.0006 to 0.0005\n",
      "[88] : train loss 0.000943, val loss drop 0.0005 to 0.0004\n",
      "fold 2\n",
      "[1] : train loss 2.984785, val loss drop 10000000.0000 to 1.9835\n",
      "[2] : train loss 1.834152, val loss drop 1.9835 to 0.9116\n",
      "[3] : train loss 0.652220, val loss drop 0.9116 to 0.2942\n",
      "[6] : train loss 0.020008, val loss drop 0.2942 to 0.0937\n",
      "[7] : train loss 0.011024, val loss drop 0.0937 to 0.0069\n",
      "[8] : train loss 0.006435, val loss drop 0.0069 to 0.0048\n",
      "[9] : train loss 0.007399, val loss drop 0.0048 to 0.0038\n",
      "[14] : train loss 0.002876, val loss drop 0.0038 to 0.0018\n",
      "[15] : train loss 0.001943, val loss drop 0.0018 to 0.0016\n",
      "[20] : train loss 0.002696, val loss drop 0.0016 to 0.0009\n",
      "[33] : train loss 0.002410, val loss drop 0.0009 to 0.0008\n",
      "[47] : train loss 0.001269, val loss drop 0.0008 to 0.0006\n",
      "[91] : train loss 0.000614, val loss drop 0.0006 to 0.0003\n",
      "fold 3\n",
      "[1] : train loss 2.982869, val loss drop 10000000.0000 to 2.1626\n",
      "[2] : train loss 2.039972, val loss drop 2.1626 to 1.4183\n",
      "[3] : train loss 1.043998, val loss drop 1.4183 to 0.5652\n",
      "[4] : train loss 0.229405, val loss drop 0.5652 to 0.1597\n",
      "[6] : train loss 0.020781, val loss drop 0.1597 to 0.1563\n",
      "[7] : train loss 0.012830, val loss drop 0.1563 to 0.0130\n",
      "[8] : train loss 0.007487, val loss drop 0.0130 to 0.0119\n",
      "[10] : train loss 0.005191, val loss drop 0.0119 to 0.0045\n",
      "[12] : train loss 0.002882, val loss drop 0.0045 to 0.0030\n",
      "[20] : train loss 0.001818, val loss drop 0.0030 to 0.0018\n",
      "[25] : train loss 0.001750, val loss drop 0.0018 to 0.0012\n",
      "[29] : train loss 0.001478, val loss drop 0.0012 to 0.0010\n",
      "[44] : train loss 0.001729, val loss drop 0.0010 to 0.0010\n",
      "[56] : train loss 0.001192, val loss drop 0.0010 to 0.0010\n",
      "[61] : train loss 0.001308, val loss drop 0.0010 to 0.0008\n",
      "[70] : train loss 0.001110, val loss drop 0.0008 to 0.0006\n",
      "[76] : train loss 0.001814, val loss drop 0.0006 to 0.0005\n",
      "[82] : train loss 0.000851, val loss drop 0.0005 to 0.0004\n",
      "[92] : train loss 0.001133, val loss drop 0.0004 to 0.0003\n",
      "fold 4\n",
      "[1] : train loss 3.073203, val loss drop 10000000.0000 to 2.4033\n",
      "[2] : train loss 2.121946, val loss drop 2.4033 to 1.0347\n",
      "[3] : train loss 0.879711, val loss drop 1.0347 to 0.5437\n",
      "[4] : train loss 0.253572, val loss drop 0.5437 to 0.4073\n",
      "[5] : train loss 0.049461, val loss drop 0.4073 to 0.1042\n",
      "[6] : train loss 0.018259, val loss drop 0.1042 to 0.0544\n",
      "[7] : train loss 0.012315, val loss drop 0.0544 to 0.0087\n",
      "[8] : train loss 0.006494, val loss drop 0.0087 to 0.0053\n",
      "[10] : train loss 0.003566, val loss drop 0.0053 to 0.0032\n",
      "[18] : train loss 0.002600, val loss drop 0.0032 to 0.0026\n",
      "[24] : train loss 0.002542, val loss drop 0.0026 to 0.0014\n",
      "[31] : train loss 0.001139, val loss drop 0.0014 to 0.0013\n",
      "[38] : train loss 0.001922, val loss drop 0.0013 to 0.0009\n",
      "[40] : train loss 0.001497, val loss drop 0.0009 to 0.0009\n",
      "[55] : train loss 0.000705, val loss drop 0.0009 to 0.0007\n",
      "[56] : train loss 0.000640, val loss drop 0.0007 to 0.0005\n",
      "[76] : train loss 0.000759, val loss drop 0.0005 to 0.0005\n",
      "[80] : train loss 0.000611, val loss drop 0.0005 to 0.0004\n",
      "fold 5\n",
      "[1] : train loss 3.095000, val loss drop 10000000.0000 to 2.3733\n",
      "[2] : train loss 2.349694, val loss drop 2.3733 to 1.5467\n",
      "[3] : train loss 1.480114, val loss drop 1.5467 to 0.8764\n",
      "[4] : train loss 0.759767, val loss drop 0.8764 to 0.4563\n",
      "[5] : train loss 0.341672, val loss drop 0.4563 to 0.1815\n",
      "[6] : train loss 0.083304, val loss drop 0.1815 to 0.0538\n",
      "[7] : train loss 0.023380, val loss drop 0.0538 to 0.0392\n",
      "[8] : train loss 0.014111, val loss drop 0.0392 to 0.0181\n",
      "[9] : train loss 0.010084, val loss drop 0.0181 to 0.0070\n",
      "[11] : train loss 0.006244, val loss drop 0.0070 to 0.0053\n",
      "[14] : train loss 0.003581, val loss drop 0.0053 to 0.0048\n",
      "[15] : train loss 0.004035, val loss drop 0.0048 to 0.0033\n",
      "[18] : train loss 0.003766, val loss drop 0.0033 to 0.0019\n",
      "[32] : train loss 0.001774, val loss drop 0.0019 to 0.0012\n",
      "[34] : train loss 0.002155, val loss drop 0.0012 to 0.0009\n",
      "[43] : train loss 0.001492, val loss drop 0.0009 to 0.0008\n",
      "[59] : train loss 0.000476, val loss drop 0.0008 to 0.0006\n",
      "[63] : train loss 0.001077, val loss drop 0.0006 to 0.0006\n",
      "[73] : train loss 0.000825, val loss drop 0.0006 to 0.0004\n",
      "[95] : train loss 0.000869, val loss drop 0.0004 to 0.0004\n",
      "fold 6\n",
      "[1] : train loss 2.915508, val loss drop 10000000.0000 to 2.1269\n",
      "[2] : train loss 1.788130, val loss drop 2.1269 to 0.7173\n",
      "[3] : train loss 0.624947, val loss drop 0.7173 to 0.2556\n",
      "[4] : train loss 0.136257, val loss drop 0.2556 to 0.0926\n",
      "[6] : train loss 0.015207, val loss drop 0.0926 to 0.0186\n",
      "[7] : train loss 0.008634, val loss drop 0.0186 to 0.0079\n",
      "[9] : train loss 0.003670, val loss drop 0.0079 to 0.0056\n",
      "[12] : train loss 0.002699, val loss drop 0.0056 to 0.0034\n",
      "[13] : train loss 0.002301, val loss drop 0.0034 to 0.0020\n",
      "[17] : train loss 0.003691, val loss drop 0.0020 to 0.0016\n",
      "[20] : train loss 0.001893, val loss drop 0.0016 to 0.0015\n",
      "[24] : train loss 0.002631, val loss drop 0.0015 to 0.0012\n",
      "[33] : train loss 0.000787, val loss drop 0.0012 to 0.0010\n",
      "[62] : train loss 0.001235, val loss drop 0.0010 to 0.0008\n",
      "[67] : train loss 0.001263, val loss drop 0.0008 to 0.0005\n",
      "[93] : train loss 0.000769, val loss drop 0.0005 to 0.0005\n",
      "[96] : train loss 0.000567, val loss drop 0.0005 to 0.0004\n",
      "fold 7\n",
      "[1] : train loss 2.986498, val loss drop 10000000.0000 to 2.2604\n",
      "[2] : train loss 1.916857, val loss drop 2.2604 to 1.2481\n",
      "[3] : train loss 0.937585, val loss drop 1.2481 to 0.7560\n",
      "[4] : train loss 0.479002, val loss drop 0.7560 to 0.5467\n",
      "[5] : train loss 0.124541, val loss drop 0.5467 to 0.1168\n",
      "[6] : train loss 0.028786, val loss drop 0.1168 to 0.0511\n",
      "[7] : train loss 0.014040, val loss drop 0.0511 to 0.0187\n",
      "[8] : train loss 0.008740, val loss drop 0.0187 to 0.0113\n",
      "[9] : train loss 0.006157, val loss drop 0.0113 to 0.0047\n",
      "[11] : train loss 0.004920, val loss drop 0.0047 to 0.0045\n",
      "[13] : train loss 0.003865, val loss drop 0.0045 to 0.0032\n",
      "[16] : train loss 0.002194, val loss drop 0.0032 to 0.0018\n",
      "[17] : train loss 0.001814, val loss drop 0.0018 to 0.0013\n",
      "[23] : train loss 0.001897, val loss drop 0.0013 to 0.0012\n",
      "[24] : train loss 0.001348, val loss drop 0.0012 to 0.0012\n",
      "[31] : train loss 0.001257, val loss drop 0.0012 to 0.0008\n",
      "[50] : train loss 0.001240, val loss drop 0.0008 to 0.0007\n",
      "[56] : train loss 0.001183, val loss drop 0.0007 to 0.0004\n",
      "[80] : train loss 0.000632, val loss drop 0.0004 to 0.0003\n",
      "fold 8\n",
      "[1] : train loss 2.981261, val loss drop 10000000.0000 to 2.2960\n",
      "[2] : train loss 1.935623, val loss drop 2.2960 to 1.4690\n",
      "[3] : train loss 0.863577, val loss drop 1.4690 to 0.4219\n",
      "[5] : train loss 0.028996, val loss drop 0.4219 to 0.2546\n",
      "[6] : train loss 0.013520, val loss drop 0.2546 to 0.1144\n",
      "[7] : train loss 0.007310, val loss drop 0.1144 to 0.0414\n",
      "[8] : train loss 0.005938, val loss drop 0.0414 to 0.0116\n",
      "[9] : train loss 0.004518, val loss drop 0.0116 to 0.0062\n",
      "[10] : train loss 0.004255, val loss drop 0.0062 to 0.0047\n",
      "[11] : train loss 0.004964, val loss drop 0.0047 to 0.0040\n",
      "[14] : train loss 0.006517, val loss drop 0.0040 to 0.0040\n",
      "[16] : train loss 0.002211, val loss drop 0.0040 to 0.0017\n",
      "[19] : train loss 0.001821, val loss drop 0.0017 to 0.0014\n",
      "[23] : train loss 0.001294, val loss drop 0.0014 to 0.0011\n",
      "[35] : train loss 0.001114, val loss drop 0.0011 to 0.0007\n",
      "[68] : train loss 0.000924, val loss drop 0.0007 to 0.0006\n",
      "[82] : train loss 0.000717, val loss drop 0.0006 to 0.0004\n",
      "[97] : train loss 0.001086, val loss drop 0.0004 to 0.0003\n",
      "fold 9\n",
      "[1] : train loss 3.038905, val loss drop 10000000.0000 to 2.4386\n",
      "[2] : train loss 2.153491, val loss drop 2.4386 to 1.2245\n",
      "[3] : train loss 0.869757, val loss drop 1.2245 to 0.2873\n",
      "[4] : train loss 0.126947, val loss drop 0.2873 to 0.2726\n",
      "[5] : train loss 0.035757, val loss drop 0.2726 to 0.1782\n",
      "[6] : train loss 0.017272, val loss drop 0.1782 to 0.0485\n",
      "[7] : train loss 0.008846, val loss drop 0.0485 to 0.0172\n",
      "[8] : train loss 0.006111, val loss drop 0.0172 to 0.0041\n",
      "[9] : train loss 0.005011, val loss drop 0.0041 to 0.0030\n",
      "[11] : train loss 0.003179, val loss drop 0.0030 to 0.0027\n",
      "[16] : train loss 0.004256, val loss drop 0.0027 to 0.0013\n",
      "[23] : train loss 0.001691, val loss drop 0.0013 to 0.0009\n",
      "[28] : train loss 0.001532, val loss drop 0.0009 to 0.0008\n",
      "[29] : train loss 0.001687, val loss drop 0.0008 to 0.0008\n",
      "[36] : train loss 0.001573, val loss drop 0.0008 to 0.0008\n",
      "[39] : train loss 0.001476, val loss drop 0.0008 to 0.0006\n",
      "[59] : train loss 0.001729, val loss drop 0.0006 to 0.0005\n",
      "[75] : train loss 0.000629, val loss drop 0.0005 to 0.0004\n",
      "[91] : train loss 0.000758, val loss drop 0.0004 to 0.0004\n",
      "[98] : train loss 0.000530, val loss drop 0.0004 to 0.0002\n",
      "fold 10\n",
      "[1] : train loss 3.026450, val loss drop 10000000.0000 to 2.3930\n",
      "[2] : train loss 2.082253, val loss drop 2.3930 to 1.4102\n",
      "[3] : train loss 0.957669, val loss drop 1.4102 to 0.6767\n",
      "[4] : train loss 0.294551, val loss drop 0.6767 to 0.4133\n",
      "[5] : train loss 0.051001, val loss drop 0.4133 to 0.1299\n",
      "[7] : train loss 0.014805, val loss drop 0.1299 to 0.0533\n",
      "[8] : train loss 0.010715, val loss drop 0.0533 to 0.0230\n",
      "[9] : train loss 0.005709, val loss drop 0.0230 to 0.0045\n",
      "[12] : train loss 0.003951, val loss drop 0.0045 to 0.0024\n",
      "[14] : train loss 0.002474, val loss drop 0.0024 to 0.0021\n",
      "[15] : train loss 0.002237, val loss drop 0.0021 to 0.0016\n",
      "[21] : train loss 0.001681, val loss drop 0.0016 to 0.0013\n",
      "[28] : train loss 0.001245, val loss drop 0.0013 to 0.0009\n",
      "[37] : train loss 0.001965, val loss drop 0.0009 to 0.0006\n",
      "[59] : train loss 0.001366, val loss drop 0.0006 to 0.0005\n",
      "[63] : train loss 0.000985, val loss drop 0.0005 to 0.0003\n",
      "M train...\n",
      "fold 1\n",
      "[1] : train loss 71.425996, val loss drop 10000000.0000 to 32.3740\n",
      "[2] : train loss 18.379646, val loss drop 32.3740 to 13.9588\n",
      "[3] : train loss 3.370355, val loss drop 13.9588 to 13.0793\n",
      "[4] : train loss 1.643810, val loss drop 13.0793 to 11.1628\n",
      "[5] : train loss 0.893253, val loss drop 11.1628 to 2.8820\n",
      "[6] : train loss 0.685936, val loss drop 2.8820 to 1.4421\n",
      "[7] : train loss 0.460960, val loss drop 1.4421 to 0.8859\n",
      "[8] : train loss 0.461450, val loss drop 0.8859 to 0.4388\n",
      "[12] : train loss 0.214240, val loss drop 0.4388 to 0.4013\n",
      "[14] : train loss 0.229048, val loss drop 0.4013 to 0.1836\n",
      "[20] : train loss 0.162808, val loss drop 0.1836 to 0.1061\n",
      "[31] : train loss 0.107292, val loss drop 0.1061 to 0.0842\n",
      "[35] : train loss 0.168930, val loss drop 0.0842 to 0.0592\n",
      "[71] : train loss 0.115957, val loss drop 0.0592 to 0.0304\n",
      "fold 2\n",
      "[1] : train loss 47.206175, val loss drop 10000000.0000 to 16.1726\n",
      "[3] : train loss 1.734927, val loss drop 16.1726 to 9.2183\n",
      "[4] : train loss 0.793485, val loss drop 9.2183 to 2.4402\n",
      "[5] : train loss 0.613811, val loss drop 2.4402 to 1.3114\n",
      "[6] : train loss 0.453119, val loss drop 1.3114 to 0.3436\n",
      "[10] : train loss 0.293262, val loss drop 0.3436 to 0.2748\n",
      "[11] : train loss 0.407648, val loss drop 0.2748 to 0.1083\n",
      "[15] : train loss 0.182364, val loss drop 0.1083 to 0.1008\n",
      "[26] : train loss 0.143716, val loss drop 0.1008 to 0.0774\n",
      "[39] : train loss 0.153675, val loss drop 0.0774 to 0.0492\n",
      "[43] : train loss 0.188743, val loss drop 0.0492 to 0.0307\n",
      "[83] : train loss 0.137617, val loss drop 0.0307 to 0.0240\n",
      "[87] : train loss 0.065482, val loss drop 0.0240 to 0.0223\n",
      "[94] : train loss 0.195359, val loss drop 0.0223 to 0.0223\n",
      "fold 3\n",
      "[1] : train loss 43.300435, val loss drop 10000000.0000 to 14.3108\n",
      "[3] : train loss 1.473893, val loss drop 14.3108 to 7.0604\n",
      "[4] : train loss 0.830515, val loss drop 7.0604 to 4.1462\n",
      "[5] : train loss 0.577179, val loss drop 4.1462 to 1.8086\n",
      "[6] : train loss 0.456326, val loss drop 1.8086 to 0.5050\n",
      "[7] : train loss 0.316891, val loss drop 0.5050 to 0.3921\n",
      "[10] : train loss 0.440162, val loss drop 0.3921 to 0.1358\n",
      "[15] : train loss 0.512826, val loss drop 0.1358 to 0.1156\n",
      "[24] : train loss 0.129439, val loss drop 0.1156 to 0.0584\n",
      "[38] : train loss 0.280967, val loss drop 0.0584 to 0.0270\n",
      "[97] : train loss 0.108238, val loss drop 0.0270 to 0.0244\n",
      "fold 4\n",
      "[1] : train loss 82.059494, val loss drop 10000000.0000 to 41.0263\n",
      "[2] : train loss 29.116908, val loss drop 41.0263 to 8.3640\n",
      "[3] : train loss 5.013402, val loss drop 8.3640 to 5.4092\n",
      "[6] : train loss 0.767843, val loss drop 5.4092 to 1.6722\n",
      "[7] : train loss 0.503088, val loss drop 1.6722 to 0.3374\n",
      "[11] : train loss 0.346653, val loss drop 0.3374 to 0.3186\n",
      "[13] : train loss 0.296997, val loss drop 0.3186 to 0.1292\n",
      "[17] : train loss 0.260668, val loss drop 0.1292 to 0.0996\n",
      "[35] : train loss 0.183398, val loss drop 0.0996 to 0.0780\n",
      "[37] : train loss 0.113950, val loss drop 0.0780 to 0.0500\n",
      "[48] : train loss 0.124771, val loss drop 0.0500 to 0.0221\n",
      "fold 5\n",
      "[1] : train loss 53.141923, val loss drop 10000000.0000 to 26.2602\n",
      "[4] : train loss 1.050790, val loss drop 26.2602 to 5.6902\n",
      "[5] : train loss 0.740844, val loss drop 5.6902 to 1.4527\n",
      "[6] : train loss 0.489007, val loss drop 1.4527 to 1.3897\n",
      "[7] : train loss 0.416439, val loss drop 1.3897 to 0.8727\n",
      "[10] : train loss 0.395473, val loss drop 0.8727 to 0.3463\n",
      "[11] : train loss 0.240814, val loss drop 0.3463 to 0.1053\n",
      "[21] : train loss 0.131454, val loss drop 0.1053 to 0.0480\n",
      "[25] : train loss 0.118026, val loss drop 0.0480 to 0.0443\n",
      "[32] : train loss 0.102246, val loss drop 0.0443 to 0.0396\n",
      "[68] : train loss 0.060199, val loss drop 0.0396 to 0.0301\n",
      "[70] : train loss 0.108028, val loss drop 0.0301 to 0.0201\n",
      "[71] : train loss 0.147992, val loss drop 0.0201 to 0.0200\n",
      "fold 6\n",
      "[1] : train loss 73.105539, val loss drop 10000000.0000 to 27.9515\n",
      "[2] : train loss 19.700001, val loss drop 27.9515 to 12.8742\n",
      "[4] : train loss 1.681317, val loss drop 12.8742 to 11.7731\n",
      "[5] : train loss 0.935968, val loss drop 11.7731 to 2.0585\n",
      "[6] : train loss 0.604270, val loss drop 2.0585 to 0.5975\n",
      "[9] : train loss 0.328947, val loss drop 0.5975 to 0.2787\n",
      "[11] : train loss 0.147059, val loss drop 0.2787 to 0.1574\n",
      "[26] : train loss 0.207374, val loss drop 0.1574 to 0.0960\n",
      "[32] : train loss 0.285938, val loss drop 0.0960 to 0.0530\n",
      "[41] : train loss 0.360091, val loss drop 0.0530 to 0.0354\n",
      "[60] : train loss 0.117357, val loss drop 0.0354 to 0.0215\n",
      "fold 7\n",
      "[1] : train loss 63.433049, val loss drop 10000000.0000 to 25.1062\n",
      "[2] : train loss 11.123720, val loss drop 25.1062 to 22.1906\n",
      "[4] : train loss 1.754502, val loss drop 22.1906 to 8.5146\n",
      "[5] : train loss 1.090197, val loss drop 8.5146 to 3.1492\n",
      "[6] : train loss 0.711777, val loss drop 3.1492 to 1.3702\n",
      "[7] : train loss 0.518314, val loss drop 1.3702 to 0.3806\n",
      "[8] : train loss 0.363154, val loss drop 0.3806 to 0.3082\n",
      "[14] : train loss 0.288564, val loss drop 0.3082 to 0.2292\n",
      "[18] : train loss 0.170510, val loss drop 0.2292 to 0.0798\n",
      "[39] : train loss 0.201138, val loss drop 0.0798 to 0.0367\n",
      "[84] : train loss 0.074582, val loss drop 0.0367 to 0.0282\n",
      "fold 8\n",
      "[1] : train loss 81.416070, val loss drop 10000000.0000 to 53.5871\n",
      "[2] : train loss 32.375505, val loss drop 53.5871 to 11.1562\n",
      "[3] : train loss 5.136430, val loss drop 11.1562 to 4.3331\n",
      "[5] : train loss 1.064910, val loss drop 4.3331 to 2.3198\n",
      "[6] : train loss 0.593681, val loss drop 2.3198 to 2.1414\n",
      "[7] : train loss 0.456517, val loss drop 2.1414 to 0.4050\n",
      "[9] : train loss 0.321060, val loss drop 0.4050 to 0.1552\n",
      "[15] : train loss 0.231977, val loss drop 0.1552 to 0.0882\n",
      "[25] : train loss 0.166337, val loss drop 0.0882 to 0.0730\n",
      "[29] : train loss 0.097068, val loss drop 0.0730 to 0.0712\n",
      "[37] : train loss 0.381817, val loss drop 0.0712 to 0.0646\n",
      "[38] : train loss 0.177529, val loss drop 0.0646 to 0.0403\n",
      "[48] : train loss 0.106750, val loss drop 0.0403 to 0.0245\n",
      "[73] : train loss 0.117170, val loss drop 0.0245 to 0.0229\n",
      "fold 9\n",
      "[1] : train loss 61.259990, val loss drop 10000000.0000 to 38.9148\n",
      "[2] : train loss 11.334188, val loss drop 38.9148 to 34.3090\n",
      "[3] : train loss 2.787451, val loss drop 34.3090 to 11.1982\n",
      "[4] : train loss 1.264641, val loss drop 11.1982 to 3.2285\n",
      "[6] : train loss 0.502881, val loss drop 3.2285 to 2.1356\n",
      "[7] : train loss 0.385791, val loss drop 2.1356 to 0.4500\n",
      "[9] : train loss 0.287976, val loss drop 0.4500 to 0.3300\n",
      "[12] : train loss 0.262575, val loss drop 0.3300 to 0.3067\n",
      "[13] : train loss 0.394450, val loss drop 0.3067 to 0.2831\n",
      "[16] : train loss 0.265879, val loss drop 0.2831 to 0.1145\n",
      "[20] : train loss 0.266841, val loss drop 0.1145 to 0.0623\n",
      "[27] : train loss 0.119403, val loss drop 0.0623 to 0.0358\n",
      "[34] : train loss 0.223865, val loss drop 0.0358 to 0.0302\n",
      "[47] : train loss 0.124366, val loss drop 0.0302 to 0.0281\n",
      "[54] : train loss 0.103281, val loss drop 0.0281 to 0.0272\n",
      "[56] : train loss 0.280700, val loss drop 0.0272 to 0.0230\n",
      "fold 10\n",
      "[1] : train loss 60.593193, val loss drop 10000000.0000 to 49.0562\n",
      "[2] : train loss 10.341467, val loss drop 49.0562 to 19.6331\n",
      "[3] : train loss 2.799189, val loss drop 19.6331 to 8.9258\n",
      "[4] : train loss 1.267455, val loss drop 8.9258 to 2.0237\n",
      "[6] : train loss 0.670101, val loss drop 2.0237 to 0.6172\n",
      "[8] : train loss 0.484910, val loss drop 0.6172 to 0.2813\n",
      "[9] : train loss 0.332699, val loss drop 0.2813 to 0.1622\n",
      "[10] : train loss 0.335564, val loss drop 0.1622 to 0.1403\n",
      "[19] : train loss 0.208457, val loss drop 0.1403 to 0.0595\n",
      "[30] : train loss 0.126152, val loss drop 0.0595 to 0.0538\n",
      "[34] : train loss 0.285449, val loss drop 0.0538 to 0.0447\n",
      "[36] : train loss 0.083853, val loss drop 0.0447 to 0.0305\n",
      "[82] : train loss 0.108770, val loss drop 0.0305 to 0.0296\n",
      "[85] : train loss 0.125953, val loss drop 0.0296 to 0.0236\n",
      "V train...\n",
      "fold 1\n",
      "[1] : train loss 3.498565, val loss drop 10000000.0000 to 0.7184\n",
      "[2] : train loss 0.215912, val loss drop 0.7184 to 0.1506\n",
      "[3] : train loss 0.076097, val loss drop 0.1506 to 0.0468\n",
      "[4] : train loss 0.042781, val loss drop 0.0468 to 0.0354\n",
      "[5] : train loss 0.022489, val loss drop 0.0354 to 0.0225\n",
      "[6] : train loss 0.014355, val loss drop 0.0225 to 0.0195\n",
      "[7] : train loss 0.011739, val loss drop 0.0195 to 0.0127\n",
      "[9] : train loss 0.007099, val loss drop 0.0127 to 0.0102\n",
      "[11] : train loss 0.006308, val loss drop 0.0102 to 0.0100\n",
      "[13] : train loss 0.005836, val loss drop 0.0100 to 0.0074\n",
      "[17] : train loss 0.004639, val loss drop 0.0074 to 0.0063\n",
      "[22] : train loss 0.003423, val loss drop 0.0063 to 0.0060\n",
      "[32] : train loss 0.002200, val loss drop 0.0060 to 0.0050\n",
      "[35] : train loss 0.003995, val loss drop 0.0050 to 0.0048\n",
      "[38] : train loss 0.001815, val loss drop 0.0048 to 0.0042\n",
      "[52] : train loss 0.001550, val loss drop 0.0042 to 0.0038\n",
      "[60] : train loss 0.002113, val loss drop 0.0038 to 0.0037\n",
      "[63] : train loss 0.001261, val loss drop 0.0037 to 0.0034\n",
      "[74] : train loss 0.001167, val loss drop 0.0034 to 0.0031\n",
      "[78] : train loss 0.002333, val loss drop 0.0031 to 0.0030\n",
      "[94] : train loss 0.001183, val loss drop 0.0030 to 0.0029\n",
      "fold 2\n",
      "[1] : train loss 3.954753, val loss drop 10000000.0000 to 1.0102\n",
      "[2] : train loss 0.330294, val loss drop 1.0102 to 0.4182\n",
      "[3] : train loss 0.112813, val loss drop 0.4182 to 0.1122\n",
      "[4] : train loss 0.053444, val loss drop 0.1122 to 0.0659\n",
      "[5] : train loss 0.033281, val loss drop 0.0659 to 0.0452\n",
      "[6] : train loss 0.023203, val loss drop 0.0452 to 0.0253\n",
      "[7] : train loss 0.017406, val loss drop 0.0253 to 0.0207\n",
      "[8] : train loss 0.013912, val loss drop 0.0207 to 0.0153\n",
      "[11] : train loss 0.009105, val loss drop 0.0153 to 0.0121\n",
      "[15] : train loss 0.007784, val loss drop 0.0121 to 0.0114\n",
      "[16] : train loss 0.006277, val loss drop 0.0114 to 0.0096\n",
      "[18] : train loss 0.005328, val loss drop 0.0096 to 0.0080\n",
      "[20] : train loss 0.006418, val loss drop 0.0080 to 0.0073\n",
      "[23] : train loss 0.006009, val loss drop 0.0073 to 0.0062\n",
      "[32] : train loss 0.003555, val loss drop 0.0062 to 0.0061\n",
      "[34] : train loss 0.004295, val loss drop 0.0061 to 0.0052\n",
      "[41] : train loss 0.003617, val loss drop 0.0052 to 0.0048\n",
      "[51] : train loss 0.007427, val loss drop 0.0048 to 0.0044\n",
      "[53] : train loss 0.004266, val loss drop 0.0044 to 0.0040\n",
      "[60] : train loss 0.004376, val loss drop 0.0040 to 0.0037\n",
      "[62] : train loss 0.001935, val loss drop 0.0037 to 0.0035\n",
      "[70] : train loss 0.001839, val loss drop 0.0035 to 0.0030\n",
      "[78] : train loss 0.001730, val loss drop 0.0030 to 0.0026\n",
      "[100] : train loss 0.002143, val loss drop 0.0026 to 0.0026\n",
      "fold 3\n",
      "[1] : train loss 4.022215, val loss drop 10000000.0000 to 0.8674\n",
      "[2] : train loss 0.139302, val loss drop 0.8674 to 0.1375\n",
      "[3] : train loss 0.055856, val loss drop 0.1375 to 0.0487\n",
      "[4] : train loss 0.032483, val loss drop 0.0487 to 0.0280\n",
      "[5] : train loss 0.019582, val loss drop 0.0280 to 0.0169\n",
      "[6] : train loss 0.014154, val loss drop 0.0169 to 0.0140\n",
      "[7] : train loss 0.010445, val loss drop 0.0140 to 0.0131\n",
      "[9] : train loss 0.007114, val loss drop 0.0131 to 0.0084\n",
      "[12] : train loss 0.005485, val loss drop 0.0084 to 0.0077\n",
      "[14] : train loss 0.006075, val loss drop 0.0077 to 0.0071\n",
      "[16] : train loss 0.005077, val loss drop 0.0071 to 0.0069\n",
      "[20] : train loss 0.005925, val loss drop 0.0069 to 0.0053\n",
      "[21] : train loss 0.003821, val loss drop 0.0053 to 0.0048\n",
      "[23] : train loss 0.003212, val loss drop 0.0048 to 0.0044\n",
      "[28] : train loss 0.004017, val loss drop 0.0044 to 0.0038\n"
     ]
    }
   ],
   "source": [
    "loss_per_model = {}\n",
    "for name in ['XY','M','V']:\n",
    "    print('{} train...'.format(name))\n",
    "    \n",
    "    # make dataset\n",
    "    train_target = train_t[list(name)].values#.astype(np.float32)\n",
    "\n",
    "    # trainx, valx, trainy, valy = train_test_split(train_f, train_target, test_size = 0.2, shuffle = True, random_state = 38)\n",
    "    fold = KFold(nfold, shuffle = True, random_state= 25)\n",
    "    loss_per_cv = []\n",
    "    for i, (train_idx, val_idx) in enumerate(fold.split(train_f, y = train_target)):\n",
    "        print('fold {}'.format(i+1))\n",
    "        trainx = train_f[train_idx]\n",
    "        valx = train_f[val_idx]\n",
    "        trainy = train_target[train_idx]\n",
    "        valy = train_target[val_idx]\n",
    "        \n",
    "        train_dataset = dfDataset(trainx.astype(np.float32), trainy)\n",
    "        train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "        val_dataset = dfDataset(valx.astype(np.float32), valy)\n",
    "        val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "        #fc = classifier([128, 64, 32, 16], input_size = 256*2*5, output_size = len(name))\n",
    "        #conv = conv_block([32, 64, 128, 256, 256, 256, 256], [1, 375, 5], (3, 1))\n",
    "        conv = conv_block([16, 32, 64, 128, 256, 256, 256], [1, 375, 5], (3, 1))\n",
    "        fc = classifier([128, 64, 32, 16], input_size = 256*1*5, output_size = len(name))\n",
    "        # define model\n",
    "        model = cnn_model(conv, fc)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = base_lr)\n",
    "\n",
    "        if name == 'XY':\n",
    "            criterion = E1_loss\n",
    "        else:\n",
    "            criterion = E2_loss\n",
    "\n",
    "        model = model.cuda()\n",
    "        if initialize:\n",
    "            model.apply(weights_init)\n",
    "\n",
    "        curr_loss = 1e+7\n",
    "        os.makedirs(save_path) if not os.path.exists(save_path) else None\n",
    "        #train\n",
    "        for ep in range(1, EPOCH + 1):\n",
    "            model.train()\n",
    "            loss = train_model(model, train_loader, criterion, optimizer, criterion)\n",
    "            model.eval()\n",
    "            val_loss =eval_model(model, val_loader, criterion)\n",
    "            if curr_loss > val_loss:\n",
    "                print('[{}] : train loss {:4f}, val loss drop {:.4f} to {:.4f}'.format(ep, np.mean(loss), curr_loss, val_loss))\n",
    "                curr_loss = val_loss\n",
    "                torch.save(model.state_dict(), os.path.join(save_path, 'model_{}_fold{}.pt'.format(name, i+1)))\n",
    "        loss_per_cv.append(curr_loss)\n",
    "    loss_per_model[name] = loss_per_cv           \n",
    "            #else:\n",
    "                #print('[{}] : train loss {:.4f}, val loss {:.4f}, not drop'.format(ep, np.mean(loss), val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_path, 'loss_info.json'), 'w') as f:\n",
    "    for k in loss_per_model:\n",
    "        loss_per_model[k] = np.mean(loss_per_model[k])\n",
    "    f.write(json.dumps(loss_per_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(os.path.join(root_dir, 'sample_submission.csv'))\n",
    "for name in ['XY','M','V']:\n",
    "    fc = classifier([128, 64, 32, 16], input_size = 512*3*5, output_size = len(name))\n",
    "    conv = conv_block([16, 32, 64, 128, 256, 512], [1, 375, 5], (3, 1))\n",
    "    # define model\n",
    "    model = cnn_model(conv, fc)\n",
    "    pred_array = []\n",
    "    for i in range(1, nfold + 1):\n",
    "        model.load_state_dict(torch.load(os.path.join(save_path, 'model_{}_fold{}.pt'.format(name, i))))\n",
    "        model = model.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predict = model(test_f.cuda())\n",
    "        pred_array.append(predict.detach().cpu().numpy())\n",
    "    submission[list(name)] = np.mean(pred_array, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>M</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2800</td>\n",
       "      <td>-261.139008</td>\n",
       "      <td>-39.881229</td>\n",
       "      <td>111.966736</td>\n",
       "      <td>0.434986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2801</td>\n",
       "      <td>316.171234</td>\n",
       "      <td>-286.514954</td>\n",
       "      <td>90.317627</td>\n",
       "      <td>0.421709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2802</td>\n",
       "      <td>-233.366653</td>\n",
       "      <td>128.657593</td>\n",
       "      <td>28.895294</td>\n",
       "      <td>0.357899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2803</td>\n",
       "      <td>160.693039</td>\n",
       "      <td>276.158539</td>\n",
       "      <td>27.653961</td>\n",
       "      <td>0.372838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2804</td>\n",
       "      <td>-170.325470</td>\n",
       "      <td>187.950928</td>\n",
       "      <td>133.650543</td>\n",
       "      <td>0.478190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id           X           Y           M         V\n",
       "0  2800 -261.139008  -39.881229  111.966736  0.434986\n",
       "1  2801  316.171234 -286.514954   90.317627  0.421709\n",
       "2  2802 -233.366653  128.657593   28.895294  0.357899\n",
       "3  2803  160.693039  276.158539   27.653961  0.372838\n",
       "4  2804 -170.325470  187.950928  133.650543  0.478190"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(os.path.join(save_path, 'submit.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 10)\n",
    "y = torch.randn(1, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
