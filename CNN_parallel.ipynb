{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import platform\n",
    "plt.style.use('seaborn')\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "from metric import E1_loss, E2_loss, total_loss\n",
    "from models import classifier, cnn_model, conv_block, cnn_parallel\n",
    "from utils import train_model, eval_model, dfDataset, weights_init\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- parallel cnn 구현\n",
    "- lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 100\n",
    "base_lr = 0.001\n",
    "now = datetime.strftime(datetime.now(), '%Y%m%d-%H%M%S')\n",
    "save_path = './model/{}'.format(now)\n",
    "initialize = True\n",
    "print_summary = True\n",
    "batch_size = 256\n",
    "nfold = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == 'Windows':\n",
    "    root_dir = 'D:/datasets/KAERI_dataset/'\n",
    "else:\n",
    "    root_dir = '/home/bskim/project/kaeri/KAERI_dataset/'\n",
    "\n",
    "train_f = pd.read_csv(os.path.join(root_dir, 'train_features.csv'))\n",
    "train_t = pd.read_csv(os.path.join(root_dir, 'train_target.csv'))\n",
    "test_f = pd.read_csv(os.path.join(root_dir, 'test_features.csv'))\n",
    "\n",
    "train_f = train_f[['Time','S1','S2','S3','S4']].values\n",
    "train_f = train_f.reshape((-1, 1, 375, 5))#.astype(np.float32)\n",
    "\n",
    "test_f = test_f[['Time','S1','S2','S3','S4']].values\n",
    "test_f = test_f.reshape((-1, 1, 375, 5))#.astype(np.float32)\n",
    "test_f = torch.FloatTensor(test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XY train...\n",
      "fold 1\n",
      "[1] : train loss 2.373179, val loss drop 10000000.0000 to 1.5837\n",
      "[2] : train loss 1.157303, val loss drop 1.5837 to 0.8538\n",
      "[3] : train loss 0.546648, val loss drop 0.8538 to 0.3697\n",
      "[4] : train loss 0.260515, val loss drop 0.3697 to 0.2026\n",
      "[5] : train loss 0.138248, val loss drop 0.2026 to 0.1709\n",
      "[6] : train loss 0.097372, val loss drop 0.1709 to 0.1159\n",
      "[7] : train loss 0.069203, val loss drop 0.1159 to 0.0800\n",
      "[8] : train loss 0.053678, val loss drop 0.0800 to 0.0523\n",
      "[11] : train loss 0.027262, val loss drop 0.0523 to 0.0377\n",
      "[13] : train loss 0.021589, val loss drop 0.0377 to 0.0331\n",
      "[15] : train loss 0.016215, val loss drop 0.0331 to 0.0193\n",
      "[19] : train loss 0.013402, val loss drop 0.0193 to 0.0185\n",
      "[21] : train loss 0.010613, val loss drop 0.0185 to 0.0171\n",
      "[26] : train loss 0.005776, val loss drop 0.0171 to 0.0131\n",
      "[27] : train loss 0.005212, val loss drop 0.0131 to 0.0113\n",
      "[28] : train loss 0.004552, val loss drop 0.0113 to 0.0110\n",
      "[30] : train loss 0.005181, val loss drop 0.0110 to 0.0098\n",
      "[32] : train loss 0.003655, val loss drop 0.0098 to 0.0097\n",
      "[37] : train loss 0.003903, val loss drop 0.0097 to 0.0092\n",
      "[39] : train loss 0.003060, val loss drop 0.0092 to 0.0076\n",
      "[54] : train loss 0.002219, val loss drop 0.0076 to 0.0049\n",
      "fold 2\n",
      "[1] : train loss 2.343888, val loss drop 10000000.0000 to 1.0036\n",
      "[2] : train loss 0.814495, val loss drop 1.0036 to 0.4591\n",
      "[3] : train loss 0.338720, val loss drop 0.4591 to 0.2107\n",
      "[4] : train loss 0.167017, val loss drop 0.2107 to 0.1297\n",
      "[5] : train loss 0.105785, val loss drop 0.1297 to 0.1277\n",
      "[6] : train loss 0.068306, val loss drop 0.1277 to 0.0528\n",
      "[8] : train loss 0.036338, val loss drop 0.0528 to 0.0322\n",
      "[11] : train loss 0.025106, val loss drop 0.0322 to 0.0223\n",
      "[12] : train loss 0.017719, val loss drop 0.0223 to 0.0185\n",
      "[16] : train loss 0.010748, val loss drop 0.0185 to 0.0120\n",
      "[17] : train loss 0.009691, val loss drop 0.0120 to 0.0103\n",
      "[19] : train loss 0.006603, val loss drop 0.0103 to 0.0100\n",
      "[23] : train loss 0.005919, val loss drop 0.0100 to 0.0092\n",
      "[27] : train loss 0.004456, val loss drop 0.0092 to 0.0074\n",
      "[28] : train loss 0.003929, val loss drop 0.0074 to 0.0070\n",
      "[33] : train loss 0.003777, val loss drop 0.0070 to 0.0050\n",
      "[42] : train loss 0.003847, val loss drop 0.0050 to 0.0043\n",
      "[47] : train loss 0.001824, val loss drop 0.0043 to 0.0039\n",
      "[73] : train loss 0.003050, val loss drop 0.0039 to 0.0035\n",
      "[89] : train loss 0.002406, val loss drop 0.0035 to 0.0033\n",
      "fold 3\n",
      "[1] : train loss 2.433678, val loss drop 10000000.0000 to 1.7533\n",
      "[2] : train loss 1.127510, val loss drop 1.7533 to 0.7176\n",
      "[3] : train loss 0.456320, val loss drop 0.7176 to 0.1873\n",
      "[4] : train loss 0.186804, val loss drop 0.1873 to 0.1407\n",
      "[5] : train loss 0.102020, val loss drop 0.1407 to 0.0631\n",
      "[6] : train loss 0.069265, val loss drop 0.0631 to 0.0484\n",
      "[7] : train loss 0.056711, val loss drop 0.0484 to 0.0445\n",
      "[8] : train loss 0.040154, val loss drop 0.0445 to 0.0389\n",
      "[9] : train loss 0.030445, val loss drop 0.0389 to 0.0273\n",
      "[10] : train loss 0.025706, val loss drop 0.0273 to 0.0226\n",
      "[11] : train loss 0.021132, val loss drop 0.0226 to 0.0204\n",
      "[12] : train loss 0.018795, val loss drop 0.0204 to 0.0163\n",
      "[13] : train loss 0.016513, val loss drop 0.0163 to 0.0135\n",
      "[21] : train loss 0.006980, val loss drop 0.0135 to 0.0133\n",
      "[22] : train loss 0.007697, val loss drop 0.0133 to 0.0111\n",
      "[26] : train loss 0.006626, val loss drop 0.0111 to 0.0104\n",
      "[27] : train loss 0.005183, val loss drop 0.0104 to 0.0082\n",
      "[29] : train loss 0.003770, val loss drop 0.0082 to 0.0073\n",
      "[30] : train loss 0.004050, val loss drop 0.0073 to 0.0061\n",
      "[36] : train loss 0.003864, val loss drop 0.0061 to 0.0060\n",
      "[46] : train loss 0.002658, val loss drop 0.0060 to 0.0056\n",
      "[48] : train loss 0.002054, val loss drop 0.0056 to 0.0052\n",
      "[57] : train loss 0.002264, val loss drop 0.0052 to 0.0047\n",
      "[65] : train loss 0.002515, val loss drop 0.0047 to 0.0044\n",
      "fold 4\n",
      "[1] : train loss 2.453037, val loss drop 10000000.0000 to 1.5105\n",
      "[2] : train loss 1.041378, val loss drop 1.5105 to 0.6745\n",
      "[3] : train loss 0.482152, val loss drop 0.6745 to 0.2994\n",
      "[4] : train loss 0.243417, val loss drop 0.2994 to 0.1389\n",
      "[6] : train loss 0.082302, val loss drop 0.1389 to 0.0864\n",
      "[7] : train loss 0.057670, val loss drop 0.0864 to 0.0563\n",
      "[9] : train loss 0.034272, val loss drop 0.0563 to 0.0349\n",
      "[12] : train loss 0.018841, val loss drop 0.0349 to 0.0319\n",
      "[13] : train loss 0.015765, val loss drop 0.0319 to 0.0188\n",
      "[16] : train loss 0.010116, val loss drop 0.0188 to 0.0160\n",
      "[19] : train loss 0.009010, val loss drop 0.0160 to 0.0145\n",
      "[20] : train loss 0.007193, val loss drop 0.0145 to 0.0099\n",
      "[31] : train loss 0.004869, val loss drop 0.0099 to 0.0094\n",
      "[34] : train loss 0.003237, val loss drop 0.0094 to 0.0078\n",
      "[35] : train loss 0.004053, val loss drop 0.0078 to 0.0071\n",
      "[49] : train loss 0.002670, val loss drop 0.0071 to 0.0068\n",
      "[54] : train loss 0.002160, val loss drop 0.0068 to 0.0062\n",
      "[61] : train loss 0.004080, val loss drop 0.0062 to 0.0061\n",
      "[64] : train loss 0.002147, val loss drop 0.0061 to 0.0058\n",
      "[91] : train loss 0.002668, val loss drop 0.0058 to 0.0045\n",
      "fold 5\n",
      "[1] : train loss 2.753258, val loss drop 10000000.0000 to 1.7664\n",
      "[2] : train loss 1.377091, val loss drop 1.7664 to 0.9217\n",
      "[3] : train loss 0.628134, val loss drop 0.9217 to 0.3529\n",
      "[4] : train loss 0.302071, val loss drop 0.3529 to 0.2481\n",
      "[5] : train loss 0.161769, val loss drop 0.2481 to 0.1282\n",
      "[6] : train loss 0.105380, val loss drop 0.1282 to 0.1069\n",
      "[7] : train loss 0.078112, val loss drop 0.1069 to 0.0488\n",
      "[9] : train loss 0.043725, val loss drop 0.0488 to 0.0469\n",
      "[10] : train loss 0.034609, val loss drop 0.0469 to 0.0444\n",
      "[11] : train loss 0.029979, val loss drop 0.0444 to 0.0308\n",
      "[13] : train loss 0.020212, val loss drop 0.0308 to 0.0267\n",
      "[14] : train loss 0.016695, val loss drop 0.0267 to 0.0231\n",
      "[15] : train loss 0.015106, val loss drop 0.0231 to 0.0169\n",
      "[17] : train loss 0.013044, val loss drop 0.0169 to 0.0145\n",
      "[19] : train loss 0.011486, val loss drop 0.0145 to 0.0130\n",
      "[22] : train loss 0.009535, val loss drop 0.0130 to 0.0119\n",
      "[26] : train loss 0.006425, val loss drop 0.0119 to 0.0098\n",
      "[28] : train loss 0.005052, val loss drop 0.0098 to 0.0095\n",
      "[37] : train loss 0.004105, val loss drop 0.0095 to 0.0072\n",
      "[41] : train loss 0.002973, val loss drop 0.0072 to 0.0062\n",
      "[51] : train loss 0.002677, val loss drop 0.0062 to 0.0060\n",
      "[56] : train loss 0.002356, val loss drop 0.0060 to 0.0058\n",
      "[69] : train loss 0.002015, val loss drop 0.0058 to 0.0050\n",
      "[76] : train loss 0.001355, val loss drop 0.0050 to 0.0047\n",
      "[79] : train loss 0.001861, val loss drop 0.0047 to 0.0047\n",
      "[84] : train loss 0.001333, val loss drop 0.0047 to 0.0041\n",
      "[89] : train loss 0.001021, val loss drop 0.0041 to 0.0040\n",
      "[92] : train loss 0.001361, val loss drop 0.0040 to 0.0034\n",
      "fold 6\n",
      "[1] : train loss 2.440842, val loss drop 10000000.0000 to 1.4318\n",
      "[2] : train loss 0.988770, val loss drop 1.4318 to 0.5249\n",
      "[3] : train loss 0.444150, val loss drop 0.5249 to 0.2607\n",
      "[4] : train loss 0.208026, val loss drop 0.2607 to 0.1348\n",
      "[5] : train loss 0.131317, val loss drop 0.1348 to 0.0993\n",
      "[6] : train loss 0.087033, val loss drop 0.0993 to 0.0669\n",
      "[8] : train loss 0.044744, val loss drop 0.0669 to 0.0415\n",
      "[10] : train loss 0.029638, val loss drop 0.0415 to 0.0388\n",
      "[12] : train loss 0.020112, val loss drop 0.0388 to 0.0254\n",
      "[13] : train loss 0.018092, val loss drop 0.0254 to 0.0236\n",
      "[15] : train loss 0.013486, val loss drop 0.0236 to 0.0200\n",
      "[17] : train loss 0.010434, val loss drop 0.0200 to 0.0163\n",
      "[18] : train loss 0.010385, val loss drop 0.0163 to 0.0138\n",
      "[20] : train loss 0.008351, val loss drop 0.0138 to 0.0125\n",
      "[21] : train loss 0.007409, val loss drop 0.0125 to 0.0121\n",
      "[25] : train loss 0.008726, val loss drop 0.0121 to 0.0108\n",
      "[29] : train loss 0.004652, val loss drop 0.0108 to 0.0074\n",
      "[40] : train loss 0.003441, val loss drop 0.0074 to 0.0065\n",
      "[42] : train loss 0.003224, val loss drop 0.0065 to 0.0062\n",
      "[70] : train loss 0.001507, val loss drop 0.0062 to 0.0055\n",
      "[72] : train loss 0.001604, val loss drop 0.0055 to 0.0047\n",
      "[81] : train loss 0.001872, val loss drop 0.0047 to 0.0047\n",
      "fold 7\n",
      "[1] : train loss 2.343169, val loss drop 10000000.0000 to 1.1994\n",
      "[2] : train loss 0.898807, val loss drop 1.1994 to 0.4014\n",
      "[3] : train loss 0.399076, val loss drop 0.4014 to 0.1982\n",
      "[4] : train loss 0.196054, val loss drop 0.1982 to 0.1525\n",
      "[5] : train loss 0.118308, val loss drop 0.1525 to 0.0747\n",
      "[6] : train loss 0.080906, val loss drop 0.0747 to 0.0536\n",
      "[7] : train loss 0.055569, val loss drop 0.0536 to 0.0442\n",
      "[8] : train loss 0.044165, val loss drop 0.0442 to 0.0319\n",
      "[10] : train loss 0.028665, val loss drop 0.0319 to 0.0238\n",
      "[12] : train loss 0.020232, val loss drop 0.0238 to 0.0211\n",
      "[15] : train loss 0.012224, val loss drop 0.0211 to 0.0155\n",
      "[16] : train loss 0.010475, val loss drop 0.0155 to 0.0106\n",
      "[18] : train loss 0.007649, val loss drop 0.0106 to 0.0097\n",
      "[22] : train loss 0.008432, val loss drop 0.0097 to 0.0097\n",
      "[28] : train loss 0.004442, val loss drop 0.0097 to 0.0050\n",
      "[54] : train loss 0.002392, val loss drop 0.0050 to 0.0048\n",
      "[58] : train loss 0.001791, val loss drop 0.0048 to 0.0031\n",
      "fold 8\n",
      "[1] : train loss 2.466518, val loss drop 10000000.0000 to 1.8044\n",
      "[2] : train loss 1.071252, val loss drop 1.8044 to 0.5919\n",
      "[3] : train loss 0.462641, val loss drop 0.5919 to 0.3724\n",
      "[4] : train loss 0.205601, val loss drop 0.3724 to 0.1897\n",
      "[5] : train loss 0.122118, val loss drop 0.1897 to 0.1158\n",
      "[6] : train loss 0.082315, val loss drop 0.1158 to 0.0700\n",
      "[8] : train loss 0.043896, val loss drop 0.0700 to 0.0450\n",
      "[9] : train loss 0.034908, val loss drop 0.0450 to 0.0413\n",
      "[10] : train loss 0.028063, val loss drop 0.0413 to 0.0287\n",
      "[13] : train loss 0.016870, val loss drop 0.0287 to 0.0196\n",
      "[15] : train loss 0.012961, val loss drop 0.0196 to 0.0160\n",
      "[17] : train loss 0.010782, val loss drop 0.0160 to 0.0134\n",
      "[19] : train loss 0.008298, val loss drop 0.0134 to 0.0133\n",
      "[24] : train loss 0.004845, val loss drop 0.0133 to 0.0093\n",
      "[33] : train loss 0.002996, val loss drop 0.0093 to 0.0068\n",
      "[42] : train loss 0.003105, val loss drop 0.0068 to 0.0054\n",
      "[61] : train loss 0.002574, val loss drop 0.0054 to 0.0049\n",
      "[89] : train loss 0.002419, val loss drop 0.0049 to 0.0045\n",
      "[94] : train loss 0.000928, val loss drop 0.0045 to 0.0045\n",
      "fold 9\n",
      "[1] : train loss 2.490004, val loss drop 10000000.0000 to 1.5669\n",
      "[2] : train loss 1.033337, val loss drop 1.5669 to 0.5731\n",
      "[3] : train loss 0.474176, val loss drop 0.5731 to 0.2940\n",
      "[4] : train loss 0.220540, val loss drop 0.2940 to 0.1512\n",
      "[5] : train loss 0.134980, val loss drop 0.1512 to 0.1094\n",
      "[6] : train loss 0.093746, val loss drop 0.1094 to 0.0482\n",
      "[8] : train loss 0.051396, val loss drop 0.0482 to 0.0339\n",
      "[9] : train loss 0.042675, val loss drop 0.0339 to 0.0246\n",
      "[11] : train loss 0.032215, val loss drop 0.0246 to 0.0211\n",
      "[12] : train loss 0.027742, val loss drop 0.0211 to 0.0178\n",
      "[14] : train loss 0.018229, val loss drop 0.0178 to 0.0143\n",
      "[15] : train loss 0.015409, val loss drop 0.0143 to 0.0100\n",
      "[20] : train loss 0.008311, val loss drop 0.0100 to 0.0089\n",
      "[21] : train loss 0.007569, val loss drop 0.0089 to 0.0076\n",
      "[23] : train loss 0.007960, val loss drop 0.0076 to 0.0058\n",
      "[29] : train loss 0.004628, val loss drop 0.0058 to 0.0058\n",
      "[30] : train loss 0.004651, val loss drop 0.0058 to 0.0043\n",
      "[51] : train loss 0.003261, val loss drop 0.0043 to 0.0042\n",
      "[65] : train loss 0.002001, val loss drop 0.0042 to 0.0039\n",
      "[66] : train loss 0.001373, val loss drop 0.0039 to 0.0037\n",
      "fold 10\n",
      "[1] : train loss 2.645555, val loss drop 10000000.0000 to 1.8458\n",
      "[2] : train loss 1.391096, val loss drop 1.8458 to 0.9441\n",
      "[3] : train loss 0.636432, val loss drop 0.9441 to 0.3721\n",
      "[4] : train loss 0.341277, val loss drop 0.3721 to 0.1568\n",
      "[5] : train loss 0.178264, val loss drop 0.1568 to 0.1119\n",
      "[7] : train loss 0.078042, val loss drop 0.1119 to 0.0588\n",
      "[8] : train loss 0.061649, val loss drop 0.0588 to 0.0475\n",
      "[9] : train loss 0.047512, val loss drop 0.0475 to 0.0398\n",
      "[11] : train loss 0.030638, val loss drop 0.0398 to 0.0261\n",
      "[13] : train loss 0.022556, val loss drop 0.0261 to 0.0236\n",
      "[16] : train loss 0.016717, val loss drop 0.0236 to 0.0167\n",
      "[18] : train loss 0.010696, val loss drop 0.0167 to 0.0140\n",
      "[24] : train loss 0.005973, val loss drop 0.0140 to 0.0095\n",
      "[30] : train loss 0.005285, val loss drop 0.0095 to 0.0093\n",
      "[33] : train loss 0.002865, val loss drop 0.0093 to 0.0075\n",
      "[38] : train loss 0.003661, val loss drop 0.0075 to 0.0070\n",
      "[40] : train loss 0.002344, val loss drop 0.0070 to 0.0065\n",
      "[50] : train loss 0.002203, val loss drop 0.0065 to 0.0059\n",
      "[56] : train loss 0.001550, val loss drop 0.0059 to 0.0057\n",
      "[60] : train loss 0.001918, val loss drop 0.0057 to 0.0050\n",
      "[64] : train loss 0.001263, val loss drop 0.0050 to 0.0050\n",
      "[85] : train loss 0.000991, val loss drop 0.0050 to 0.0045\n",
      "M train...\n",
      "fold 1\n",
      "[1] : train loss 43.843917, val loss drop 10000000.0000 to 18.8018\n",
      "[2] : train loss 12.361518, val loss drop 18.8018 to 9.8741\n",
      "[3] : train loss 4.290030, val loss drop 9.8741 to 3.5469\n",
      "[4] : train loss 1.853195, val loss drop 3.5469 to 1.5706\n",
      "[6] : train loss 0.779374, val loss drop 1.5706 to 0.9149\n",
      "[13] : train loss 0.659549, val loss drop 0.9149 to 0.2897\n",
      "[20] : train loss 0.220068, val loss drop 0.2897 to 0.2472\n",
      "[21] : train loss 0.360185, val loss drop 0.2472 to 0.2194\n",
      "[31] : train loss 0.280384, val loss drop 0.2194 to 0.1872\n",
      "[40] : train loss 0.329347, val loss drop 0.1872 to 0.1538\n",
      "[75] : train loss 0.092207, val loss drop 0.1538 to 0.0880\n",
      "fold 2\n",
      "[1] : train loss 43.462880, val loss drop 10000000.0000 to 18.2100\n",
      "[2] : train loss 14.943831, val loss drop 18.2100 to 11.8737\n",
      "[3] : train loss 6.012061, val loss drop 11.8737 to 2.9722\n",
      "[4] : train loss 2.682190, val loss drop 2.9722 to 2.3322\n",
      "[5] : train loss 1.464159, val loss drop 2.3322 to 2.2044\n",
      "[7] : train loss 0.754418, val loss drop 2.2044 to 2.1797\n",
      "[8] : train loss 0.731089, val loss drop 2.1797 to 1.5325\n",
      "[9] : train loss 0.742884, val loss drop 1.5325 to 0.8341\n",
      "[11] : train loss 0.565269, val loss drop 0.8341 to 0.4902\n",
      "[14] : train loss 0.441205, val loss drop 0.4902 to 0.3542\n",
      "[15] : train loss 0.353476, val loss drop 0.3542 to 0.2873\n",
      "[17] : train loss 0.669098, val loss drop 0.2873 to 0.1796\n",
      "[26] : train loss 0.360193, val loss drop 0.1796 to 0.1336\n",
      "[39] : train loss 0.118083, val loss drop 0.1336 to 0.0898\n",
      "[40] : train loss 0.182243, val loss drop 0.0898 to 0.0782\n",
      "fold 3\n",
      "[1] : train loss 35.979949, val loss drop 10000000.0000 to 18.3268\n",
      "[2] : train loss 9.463136, val loss drop 18.3268 to 4.3855\n",
      "[3] : train loss 3.495625, val loss drop 4.3855 to 2.3474\n",
      "[4] : train loss 1.806377, val loss drop 2.3474 to 1.2720\n",
      "[5] : train loss 0.860255, val loss drop 1.2720 to 0.7014\n",
      "[9] : train loss 0.595902, val loss drop 0.7014 to 0.4298\n",
      "[11] : train loss 0.402353, val loss drop 0.4298 to 0.3901\n",
      "[17] : train loss 0.351588, val loss drop 0.3901 to 0.2440\n",
      "[18] : train loss 0.151035, val loss drop 0.2440 to 0.1475\n",
      "[25] : train loss 0.519949, val loss drop 0.1475 to 0.1386\n",
      "[57] : train loss 0.210960, val loss drop 0.1386 to 0.1221\n",
      "[63] : train loss 0.220911, val loss drop 0.1221 to 0.1146\n",
      "[69] : train loss 0.204727, val loss drop 0.1146 to 0.0860\n",
      "[93] : train loss 0.123203, val loss drop 0.0860 to 0.0550\n",
      "fold 4\n",
      "[1] : train loss 31.350824, val loss drop 10000000.0000 to 10.7289\n",
      "[2] : train loss 6.646737, val loss drop 10.7289 to 4.9922\n",
      "[3] : train loss 2.811554, val loss drop 4.9922 to 1.9764\n",
      "[4] : train loss 1.731059, val loss drop 1.9764 to 1.9087\n",
      "[6] : train loss 0.730600, val loss drop 1.9087 to 0.5516\n",
      "[8] : train loss 0.475767, val loss drop 0.5516 to 0.2424\n",
      "[24] : train loss 0.346938, val loss drop 0.2424 to 0.1247\n",
      "[39] : train loss 0.313681, val loss drop 0.1247 to 0.0815\n",
      "fold 5\n",
      "[1] : train loss 43.767055, val loss drop 10000000.0000 to 14.4080\n",
      "[2] : train loss 13.454525, val loss drop 14.4080 to 7.0462\n",
      "[3] : train loss 5.256424, val loss drop 7.0462 to 4.3890\n",
      "[4] : train loss 3.251518, val loss drop 4.3890 to 2.9396\n",
      "[5] : train loss 1.962466, val loss drop 2.9396 to 1.8448\n",
      "[6] : train loss 1.368626, val loss drop 1.8448 to 1.3942\n",
      "[7] : train loss 0.922171, val loss drop 1.3942 to 1.1244\n",
      "[8] : train loss 0.604694, val loss drop 1.1244 to 0.9251\n",
      "[11] : train loss 0.479898, val loss drop 0.9251 to 0.5426\n",
      "[14] : train loss 0.322704, val loss drop 0.5426 to 0.2535\n",
      "[24] : train loss 0.490104, val loss drop 0.2535 to 0.2451\n",
      "[37] : train loss 0.166017, val loss drop 0.2451 to 0.2290\n",
      "[38] : train loss 0.237491, val loss drop 0.2290 to 0.1471\n",
      "[70] : train loss 0.382783, val loss drop 0.1471 to 0.1315\n",
      "[97] : train loss 0.269861, val loss drop 0.1315 to 0.1023\n",
      "fold 6\n",
      "[1] : train loss 39.669987, val loss drop 10000000.0000 to 20.7263\n",
      "[2] : train loss 10.424937, val loss drop 20.7263 to 4.7885\n",
      "[3] : train loss 3.924163, val loss drop 4.7885 to 3.5342\n",
      "[4] : train loss 2.314998, val loss drop 3.5342 to 1.6130\n",
      "[6] : train loss 0.859665, val loss drop 1.6130 to 1.0577\n",
      "[7] : train loss 0.673929, val loss drop 1.0577 to 0.9921\n",
      "[8] : train loss 0.607509, val loss drop 0.9921 to 0.4642\n",
      "[13] : train loss 0.349741, val loss drop 0.4642 to 0.4316\n",
      "[20] : train loss 0.242061, val loss drop 0.4316 to 0.3645\n",
      "[28] : train loss 0.346608, val loss drop 0.3645 to 0.3204\n",
      "[34] : train loss 0.185362, val loss drop 0.3204 to 0.2978\n",
      "[48] : train loss 0.169734, val loss drop 0.2978 to 0.1022\n",
      "[67] : train loss 0.057099, val loss drop 0.1022 to 0.0976\n",
      "[91] : train loss 0.155393, val loss drop 0.0976 to 0.0759\n",
      "fold 7\n",
      "[1] : train loss 34.390782, val loss drop 10000000.0000 to 13.1565\n",
      "[2] : train loss 5.641136, val loss drop 13.1565 to 3.3942\n",
      "[3] : train loss 2.082193, val loss drop 3.3942 to 1.7247\n",
      "[4] : train loss 1.071471, val loss drop 1.7247 to 0.5826\n",
      "[6] : train loss 0.616826, val loss drop 0.5826 to 0.5518\n",
      "[13] : train loss 0.229183, val loss drop 0.5518 to 0.3464\n",
      "[20] : train loss 0.225631, val loss drop 0.3464 to 0.3290\n",
      "[21] : train loss 0.495894, val loss drop 0.3290 to 0.2849\n",
      "[24] : train loss 0.399366, val loss drop 0.2849 to 0.2342\n",
      "[28] : train loss 0.327658, val loss drop 0.2342 to 0.1738\n",
      "[36] : train loss 0.217960, val loss drop 0.1738 to 0.1599\n",
      "[57] : train loss 0.396356, val loss drop 0.1599 to 0.1303\n",
      "[58] : train loss 0.280067, val loss drop 0.1303 to 0.0931\n",
      "[73] : train loss 0.296247, val loss drop 0.0931 to 0.0586\n",
      "[96] : train loss 0.249753, val loss drop 0.0586 to 0.0556\n",
      "fold 8\n",
      "[1] : train loss 29.079973, val loss drop 10000000.0000 to 4.9781\n",
      "[2] : train loss 4.326925, val loss drop 4.9781 to 4.9416\n",
      "[3] : train loss 1.820002, val loss drop 4.9416 to 1.8188\n",
      "[4] : train loss 1.031743, val loss drop 1.8188 to 0.5760\n",
      "[7] : train loss 0.575172, val loss drop 0.5760 to 0.4201\n",
      "[9] : train loss 0.783561, val loss drop 0.4201 to 0.2353\n",
      "[15] : train loss 0.246095, val loss drop 0.2353 to 0.2321\n",
      "[19] : train loss 0.210001, val loss drop 0.2321 to 0.2281\n",
      "[22] : train loss 0.428592, val loss drop 0.2281 to 0.1265\n",
      "[49] : train loss 0.171659, val loss drop 0.1265 to 0.0809\n",
      "[99] : train loss 0.218448, val loss drop 0.0809 to 0.0632\n",
      "fold 9\n",
      "[1] : train loss 39.126656, val loss drop 10000000.0000 to 15.2683\n",
      "[2] : train loss 8.030023, val loss drop 15.2683 to 2.8338\n",
      "[3] : train loss 3.566515, val loss drop 2.8338 to 1.6089\n",
      "[4] : train loss 1.860800, val loss drop 1.6089 to 1.0207\n",
      "[5] : train loss 1.080289, val loss drop 1.0207 to 0.9564\n",
      "[7] : train loss 0.984466, val loss drop 0.9564 to 0.4444\n",
      "[11] : train loss 0.710899, val loss drop 0.4444 to 0.2295\n",
      "[13] : train loss 0.371949, val loss drop 0.2295 to 0.1593\n",
      "[22] : train loss 0.692385, val loss drop 0.1593 to 0.1441\n",
      "[36] : train loss 0.675344, val loss drop 0.1441 to 0.1353\n",
      "[44] : train loss 0.207984, val loss drop 0.1353 to 0.0954\n",
      "[53] : train loss 0.199970, val loss drop 0.0954 to 0.0774\n",
      "[61] : train loss 0.204443, val loss drop 0.0774 to 0.0732\n",
      "[68] : train loss 0.185462, val loss drop 0.0732 to 0.0505\n",
      "fold 10\n",
      "[1] : train loss 32.284506, val loss drop 10000000.0000 to 10.3375\n",
      "[2] : train loss 7.790749, val loss drop 10.3375 to 4.3235\n",
      "[3] : train loss 2.541454, val loss drop 4.3235 to 2.2893\n",
      "[4] : train loss 1.278067, val loss drop 2.2893 to 1.1652\n",
      "[8] : train loss 0.467318, val loss drop 1.1652 to 1.0164\n",
      "[11] : train loss 0.426118, val loss drop 1.0164 to 0.2131\n",
      "[46] : train loss 0.489617, val loss drop 0.2131 to 0.0881\n",
      "V train...\n",
      "fold 1\n",
      "[1] : train loss 21.712208, val loss drop 10000000.0000 to 1.8122\n",
      "[2] : train loss 0.703710, val loss drop 1.8122 to 0.1474\n",
      "[4] : train loss 0.173733, val loss drop 0.1474 to 0.0713\n",
      "[7] : train loss 0.055142, val loss drop 0.0713 to 0.0355\n",
      "[8] : train loss 0.034015, val loss drop 0.0355 to 0.0222\n",
      "[23] : train loss 0.015331, val loss drop 0.0222 to 0.0207\n",
      "[24] : train loss 0.021814, val loss drop 0.0207 to 0.0156\n",
      "[27] : train loss 0.015846, val loss drop 0.0156 to 0.0152\n",
      "[38] : train loss 0.021732, val loss drop 0.0152 to 0.0127\n",
      "[41] : train loss 0.012041, val loss drop 0.0127 to 0.0120\n",
      "[52] : train loss 0.024281, val loss drop 0.0120 to 0.0086\n",
      "[67] : train loss 0.005643, val loss drop 0.0086 to 0.0064\n",
      "[68] : train loss 0.005414, val loss drop 0.0064 to 0.0054\n",
      "fold 2\n",
      "[1] : train loss 23.519380, val loss drop 10000000.0000 to 1.0637\n",
      "[2] : train loss 0.844316, val loss drop 1.0637 to 0.2973\n",
      "[4] : train loss 0.241067, val loss drop 0.2973 to 0.1496\n",
      "[6] : train loss 0.097038, val loss drop 0.1496 to 0.1007\n",
      "[7] : train loss 0.084949, val loss drop 0.1007 to 0.0872\n",
      "[8] : train loss 0.081722, val loss drop 0.0872 to 0.0450\n",
      "[11] : train loss 0.034091, val loss drop 0.0450 to 0.0393\n",
      "[14] : train loss 0.023662, val loss drop 0.0393 to 0.0277\n",
      "[15] : train loss 0.022277, val loss drop 0.0277 to 0.0201\n",
      "[19] : train loss 0.032841, val loss drop 0.0201 to 0.0174\n",
      "[34] : train loss 0.032186, val loss drop 0.0174 to 0.0124\n",
      "[38] : train loss 0.020332, val loss drop 0.0124 to 0.0094\n",
      "[75] : train loss 0.019700, val loss drop 0.0094 to 0.0065\n",
      "[87] : train loss 0.004072, val loss drop 0.0065 to 0.0048\n",
      "[94] : train loss 0.013060, val loss drop 0.0048 to 0.0047\n",
      "fold 3\n",
      "[1] : train loss 32.660989, val loss drop 10000000.0000 to 2.1185\n",
      "[2] : train loss 2.146634, val loss drop 2.1185 to 1.5181\n",
      "[3] : train loss 0.849236, val loss drop 1.5181 to 0.5412\n",
      "[4] : train loss 0.319556, val loss drop 0.5412 to 0.2210\n",
      "[5] : train loss 0.179755, val loss drop 0.2210 to 0.1698\n",
      "[6] : train loss 0.116253, val loss drop 0.1698 to 0.1508\n",
      "[7] : train loss 0.075015, val loss drop 0.1508 to 0.0594\n",
      "[13] : train loss 0.052303, val loss drop 0.0594 to 0.0428\n",
      "[15] : train loss 0.051124, val loss drop 0.0428 to 0.0346\n",
      "[21] : train loss 0.019781, val loss drop 0.0346 to 0.0249\n",
      "[49] : train loss 0.022660, val loss drop 0.0249 to 0.0220\n",
      "[73] : train loss 0.018593, val loss drop 0.0220 to 0.0181\n",
      "[75] : train loss 0.006883, val loss drop 0.0181 to 0.0179\n",
      "[76] : train loss 0.021324, val loss drop 0.0179 to 0.0168\n",
      "[98] : train loss 0.056420, val loss drop 0.0168 to 0.0162\n",
      "fold 4\n",
      "[1] : train loss 74.284877, val loss drop 10000000.0000 to 4.2537\n",
      "[2] : train loss 2.282657, val loss drop 4.2537 to 1.5515\n",
      "[3] : train loss 0.814094, val loss drop 1.5515 to 0.4298\n",
      "[4] : train loss 0.314887, val loss drop 0.4298 to 0.0975\n",
      "[7] : train loss 0.056455, val loss drop 0.0975 to 0.0741\n",
      "[8] : train loss 0.043500, val loss drop 0.0741 to 0.0366\n",
      "[10] : train loss 0.031735, val loss drop 0.0366 to 0.0281\n",
      "[14] : train loss 0.017199, val loss drop 0.0281 to 0.0217\n",
      "[16] : train loss 0.015289, val loss drop 0.0217 to 0.0165\n",
      "[18] : train loss 0.024487, val loss drop 0.0165 to 0.0157\n",
      "[22] : train loss 0.009281, val loss drop 0.0157 to 0.0119\n",
      "[25] : train loss 0.009324, val loss drop 0.0119 to 0.0101\n",
      "[34] : train loss 0.006792, val loss drop 0.0101 to 0.0083\n",
      "[35] : train loss 0.005772, val loss drop 0.0083 to 0.0070\n",
      "[45] : train loss 0.006060, val loss drop 0.0070 to 0.0062\n",
      "[51] : train loss 0.006225, val loss drop 0.0062 to 0.0061\n",
      "[65] : train loss 0.003867, val loss drop 0.0061 to 0.0043\n",
      "[92] : train loss 0.004144, val loss drop 0.0043 to 0.0041\n",
      "fold 5\n",
      "[1] : train loss 14.062055, val loss drop 10000000.0000 to 0.9085\n",
      "[2] : train loss 1.086553, val loss drop 0.9085 to 0.5867\n",
      "[3] : train loss 0.628541, val loss drop 0.5867 to 0.4927\n",
      "[4] : train loss 0.404697, val loss drop 0.4927 to 0.1668\n",
      "[7] : train loss 0.127755, val loss drop 0.1668 to 0.1027\n",
      "[8] : train loss 0.067425, val loss drop 0.1027 to 0.0350\n",
      "[12] : train loss 0.038708, val loss drop 0.0350 to 0.0254\n",
      "[32] : train loss 0.085389, val loss drop 0.0254 to 0.0240\n",
      "[33] : train loss 0.057905, val loss drop 0.0240 to 0.0193\n",
      "[54] : train loss 0.014518, val loss drop 0.0193 to 0.0101\n",
      "fold 6\n",
      "[1] : train loss 15.976803, val loss drop 10000000.0000 to 0.5543\n",
      "[2] : train loss 0.421765, val loss drop 0.5543 to 0.2885\n",
      "[3] : train loss 0.154956, val loss drop 0.2885 to 0.0746\n",
      "[4] : train loss 0.055193, val loss drop 0.0746 to 0.0348\n",
      "[5] : train loss 0.034227, val loss drop 0.0348 to 0.0277\n",
      "[6] : train loss 0.018772, val loss drop 0.0277 to 0.0197\n",
      "[7] : train loss 0.015633, val loss drop 0.0197 to 0.0118\n",
      "[9] : train loss 0.011136, val loss drop 0.0118 to 0.0083\n",
      "[10] : train loss 0.009151, val loss drop 0.0083 to 0.0064\n",
      "[23] : train loss 0.006099, val loss drop 0.0064 to 0.0038\n",
      "[31] : train loss 0.006193, val loss drop 0.0038 to 0.0034\n",
      "[36] : train loss 0.003635, val loss drop 0.0034 to 0.0034\n",
      "[50] : train loss 0.003826, val loss drop 0.0034 to 0.0022\n",
      "fold 7\n",
      "[1] : train loss 44.266789, val loss drop 10000000.0000 to 4.9612\n",
      "[2] : train loss 2.226856, val loss drop 4.9612 to 1.6481\n",
      "[3] : train loss 0.767416, val loss drop 1.6481 to 0.4770\n",
      "[4] : train loss 0.350378, val loss drop 0.4770 to 0.2760\n",
      "[5] : train loss 0.160483, val loss drop 0.2760 to 0.1159\n",
      "[6] : train loss 0.080149, val loss drop 0.1159 to 0.0581\n",
      "[7] : train loss 0.050104, val loss drop 0.0581 to 0.0529\n",
      "[8] : train loss 0.035337, val loss drop 0.0529 to 0.0465\n",
      "[9] : train loss 0.029527, val loss drop 0.0465 to 0.0285\n",
      "[11] : train loss 0.025243, val loss drop 0.0285 to 0.0224\n",
      "[16] : train loss 0.015815, val loss drop 0.0224 to 0.0174\n",
      "[21] : train loss 0.010286, val loss drop 0.0174 to 0.0156\n",
      "[23] : train loss 0.011786, val loss drop 0.0156 to 0.0124\n",
      "[27] : train loss 0.007717, val loss drop 0.0124 to 0.0113\n",
      "[31] : train loss 0.006466, val loss drop 0.0113 to 0.0099\n",
      "[61] : train loss 0.004740, val loss drop 0.0099 to 0.0062\n",
      "[84] : train loss 0.003315, val loss drop 0.0062 to 0.0061\n",
      "fold 8\n",
      "[1] : train loss 16.412900, val loss drop 10000000.0000 to 2.2272\n",
      "[2] : train loss 1.531224, val loss drop 2.2272 to 1.4764\n",
      "[3] : train loss 0.984111, val loss drop 1.4764 to 0.4381\n",
      "[4] : train loss 0.474219, val loss drop 0.4381 to 0.4295\n",
      "[5] : train loss 0.237124, val loss drop 0.4295 to 0.1366\n",
      "[6] : train loss 0.090781, val loss drop 0.1366 to 0.0870\n",
      "[8] : train loss 0.044959, val loss drop 0.0870 to 0.0502\n",
      "[11] : train loss 0.029436, val loss drop 0.0502 to 0.0380\n",
      "[17] : train loss 0.016495, val loss drop 0.0380 to 0.0310\n",
      "[19] : train loss 0.016547, val loss drop 0.0310 to 0.0235\n",
      "[23] : train loss 0.024880, val loss drop 0.0235 to 0.0174\n",
      "[28] : train loss 0.012363, val loss drop 0.0174 to 0.0165\n",
      "[32] : train loss 0.016794, val loss drop 0.0165 to 0.0132\n",
      "[88] : train loss 0.016333, val loss drop 0.0132 to 0.0106\n",
      "fold 9\n",
      "[1] : train loss 9.748426, val loss drop 10000000.0000 to 2.3619\n",
      "[2] : train loss 2.113310, val loss drop 2.3619 to 1.3010\n",
      "[3] : train loss 1.121471, val loss drop 1.3010 to 0.7586\n",
      "[4] : train loss 0.512282, val loss drop 0.7586 to 0.3034\n",
      "[5] : train loss 0.230291, val loss drop 0.3034 to 0.1676\n",
      "[6] : train loss 0.118630, val loss drop 0.1676 to 0.1211\n",
      "[7] : train loss 0.077540, val loss drop 0.1211 to 0.1070\n",
      "[8] : train loss 0.056010, val loss drop 0.1070 to 0.0873\n",
      "[9] : train loss 0.062297, val loss drop 0.0873 to 0.0639\n",
      "[12] : train loss 0.052225, val loss drop 0.0639 to 0.0609\n",
      "[16] : train loss 0.032248, val loss drop 0.0609 to 0.0499\n",
      "[18] : train loss 0.026693, val loss drop 0.0499 to 0.0393\n",
      "[23] : train loss 0.022857, val loss drop 0.0393 to 0.0348\n",
      "[77] : train loss 0.032264, val loss drop 0.0348 to 0.0348\n",
      "[79] : train loss 0.039319, val loss drop 0.0348 to 0.0234\n",
      "[84] : train loss 0.034297, val loss drop 0.0234 to 0.0228\n",
      "[85] : train loss 0.018239, val loss drop 0.0228 to 0.0157\n",
      "fold 10\n",
      "[1] : train loss 21.671735, val loss drop 10000000.0000 to 0.8260\n",
      "[2] : train loss 0.588680, val loss drop 0.8260 to 0.2984\n",
      "[3] : train loss 0.300199, val loss drop 0.2984 to 0.2124\n",
      "[4] : train loss 0.189491, val loss drop 0.2124 to 0.0857\n",
      "[5] : train loss 0.090305, val loss drop 0.0857 to 0.0752\n",
      "[6] : train loss 0.058991, val loss drop 0.0752 to 0.0411\n",
      "[8] : train loss 0.030671, val loss drop 0.0411 to 0.0293\n",
      "[14] : train loss 0.037458, val loss drop 0.0293 to 0.0209\n",
      "[15] : train loss 0.027066, val loss drop 0.0209 to 0.0165\n",
      "[33] : train loss 0.014692, val loss drop 0.0165 to 0.0145\n",
      "[42] : train loss 0.015538, val loss drop 0.0145 to 0.0114\n"
     ]
    }
   ],
   "source": [
    "loss_per_model = {}\n",
    "for name in ['XY','M','V']:\n",
    "    print('{} train...'.format(name))\n",
    "    \n",
    "    # make dataset\n",
    "    train_target = train_t[list(name)].values#.astype(np.float32)\n",
    "\n",
    "    # trainx, valx, trainy, valy = train_test_split(train_f, train_target, test_size = 0.2, shuffle = True, random_state = 38)\n",
    "    fold = KFold(nfold, shuffle = True, random_state= 25)\n",
    "    loss_per_cv = []\n",
    "    for i, (train_idx, val_idx) in enumerate(fold.split(train_f, y = train_target)):\n",
    "        print('fold {}'.format(i+1))\n",
    "        trainx = train_f[train_idx]\n",
    "        valx = train_f[val_idx]\n",
    "        trainy = train_target[train_idx]\n",
    "        valy = train_target[val_idx]\n",
    "        \n",
    "        train_dataset = dfDataset(trainx.astype(np.float32), trainy)\n",
    "        train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "        val_dataset = dfDataset(valx.astype(np.float32), valy)\n",
    "        val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "        conv1 = conv_block([8, 16, 32, 64, 128], [1, 375, 5], (3, 1)).cuda() # 128 * 9 * 5\n",
    "        conv2 = conv_block([8, 16, 32, 64, 128], [1, 375, 5], (4, 1)).cuda() # 128 * 8 * 5\n",
    "        conv3 = conv_block([8, 16, 32, 64, 128], [1, 375, 5], (5, 1)).cuda() # 128 * 7 * 5\n",
    "        conv4 = conv_block([8, 16, 32, 64, 128], [1, 375, 5], (6, 1)).cuda() # 128 * 6 * 5\n",
    "\n",
    "        fc = classifier([128, 64, 32, 16], input_size = 128*30*5, output_size = len(name)).cuda()\n",
    "        fc = fc.cuda()\n",
    "\n",
    "        model = cnn_parallel([conv1, conv2, conv3, conv4], fc).cuda()\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = base_lr)\n",
    "\n",
    "        if name == 'XY':\n",
    "            criterion = E1_loss\n",
    "        else:\n",
    "            criterion = E2_loss\n",
    "\n",
    "        model = model.cuda()\n",
    "        if initialize:\n",
    "            model.apply(weights_init)\n",
    "\n",
    "        curr_loss = 1e+7\n",
    "        os.makedirs(save_path) if not os.path.exists(save_path) else None\n",
    "        #train\n",
    "        for ep in range(1, EPOCH + 1):\n",
    "            model.train()\n",
    "            loss = train_model(model, train_loader, criterion, optimizer, criterion)\n",
    "            model.eval()\n",
    "            val_loss =eval_model(model, val_loader, criterion)\n",
    "            if curr_loss > val_loss:\n",
    "                print('[{}] : train loss {:4f}, val loss drop {:.4f} to {:.4f}'.format(ep, np.mean(loss), curr_loss, val_loss))\n",
    "                curr_loss = val_loss\n",
    "                torch.save(model.state_dict(), os.path.join(save_path, 'model_{}_fold{}.pt'.format(name, i+1)))\n",
    "        loss_per_cv.append(curr_loss)\n",
    "    loss_per_model[name] = loss_per_cv           \n",
    "            #else:\n",
    "                #print('[{}] : train loss {:.4f}, val loss {:.4f}, not drop'.format(ep, np.mean(loss), val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_path, 'loss_info.json'), 'w') as f:\n",
    "    for k in loss_per_model:\n",
    "        loss_per_model[k] = np.mean(loss_per_model[k])\n",
    "    f.write(json.dumps(loss_per_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(os.path.join(root_dir, 'sample_submission.csv'))\n",
    "for name in ['XY','M','V']:\n",
    "    fc = classifier([128, 64, 32, 16], input_size = 512*3*5, output_size = len(name))\n",
    "    conv = conv_block([16, 32, 64, 128, 256, 512], [1, 375, 5], (3, 1))\n",
    "    # define model\n",
    "    model = cnn_model(conv, fc)\n",
    "    pred_array = []\n",
    "    for i in range(1, nfold + 1):\n",
    "        model.load_state_dict(torch.load(os.path.join(save_path, 'model_{}_fold{}.pt'.format(name, i))))\n",
    "        model = model.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predict = model(test_f.cuda())\n",
    "        pred_array.append(predict.detach().cpu().numpy())\n",
    "    submission[list(name)] = np.mean(pred_array, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>M</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2800</td>\n",
       "      <td>-261.139008</td>\n",
       "      <td>-39.881229</td>\n",
       "      <td>111.966736</td>\n",
       "      <td>0.434986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2801</td>\n",
       "      <td>316.171234</td>\n",
       "      <td>-286.514954</td>\n",
       "      <td>90.317627</td>\n",
       "      <td>0.421709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2802</td>\n",
       "      <td>-233.366653</td>\n",
       "      <td>128.657593</td>\n",
       "      <td>28.895294</td>\n",
       "      <td>0.357899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2803</td>\n",
       "      <td>160.693039</td>\n",
       "      <td>276.158539</td>\n",
       "      <td>27.653961</td>\n",
       "      <td>0.372838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2804</td>\n",
       "      <td>-170.325470</td>\n",
       "      <td>187.950928</td>\n",
       "      <td>133.650543</td>\n",
       "      <td>0.478190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id           X           Y           M         V\n",
       "0  2800 -261.139008  -39.881229  111.966736  0.434986\n",
       "1  2801  316.171234 -286.514954   90.317627  0.421709\n",
       "2  2802 -233.366653  128.657593   28.895294  0.357899\n",
       "3  2803  160.693039  276.158539   27.653961  0.372838\n",
       "4  2804 -170.325470  187.950928  133.650543  0.478190"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(os.path.join(save_path, 'submit.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 10)\n",
    "y = torch.randn(1, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
