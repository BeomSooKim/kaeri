{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import platform\n",
    "plt.style.use('seaborn')\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "from metric import E1_loss, E2_loss, total_loss\n",
    "from models import classifier, cnn_model, conv_block, cnn_parallel\n",
    "from utils import train_model, eval_model, dfDataset, weights_init\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 100\n",
    "base_lr = 0.001\n",
    "now = datetime.strftime(datetime.now(), '%Y%m%d-%H%M%S')\n",
    "save_path = './model/{}'.format(now)\n",
    "initialize = True\n",
    "print_summary = True\n",
    "batch_size = 256\n",
    "nfold = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == 'Windows':\n",
    "    root_dir = 'D:/datasets/KAERI_dataset/'\n",
    "else:\n",
    "    root_dir = '/home/bskim/project/kaeri/KAERI_dataset/'\n",
    "\n",
    "train_f = pd.read_csv(os.path.join(root_dir, 'train_features.csv'))\n",
    "train_t = pd.read_csv(os.path.join(root_dir, 'train_target.csv'))\n",
    "test_f = pd.read_csv(os.path.join(root_dir, 'test_features.csv'))\n",
    "\n",
    "train_f = train_f[['Time','S1','S2','S3','S4']].values\n",
    "train_f = train_f.reshape((-1, 1, 375, 5))#.astype(np.float32)\n",
    "\n",
    "test_f = test_f[['Time','S1','S2','S3','S4']].values\n",
    "test_f = test_f.reshape((-1, 1, 375, 5))#.astype(np.float32)\n",
    "test_f = torch.FloatTensor(test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XY train...\n",
      "fold 1\n",
      "[1] : train loss 2.973700, val loss drop 10000000.0000 to 2.2627\n",
      "[2] : train loss 1.824854, val loss drop 2.2627 to 0.8012\n",
      "[3] : train loss 0.496061, val loss drop 0.8012 to 0.3402\n",
      "[5] : train loss 0.024229, val loss drop 0.3402 to 0.1148\n",
      "[6] : train loss 0.010454, val loss drop 0.1148 to 0.0175\n",
      "[8] : train loss 0.005938, val loss drop 0.0175 to 0.0095\n",
      "[10] : train loss 0.004702, val loss drop 0.0095 to 0.0041\n",
      "[13] : train loss 0.002094, val loss drop 0.0041 to 0.0030\n",
      "[21] : train loss 0.002617, val loss drop 0.0030 to 0.0020\n",
      "[22] : train loss 0.002724, val loss drop 0.0020 to 0.0015\n",
      "[29] : train loss 0.002374, val loss drop 0.0015 to 0.0015\n",
      "[30] : train loss 0.001645, val loss drop 0.0015 to 0.0013\n",
      "[39] : train loss 0.000965, val loss drop 0.0013 to 0.0011\n",
      "[50] : train loss 0.001447, val loss drop 0.0011 to 0.0009\n",
      "[51] : train loss 0.000649, val loss drop 0.0009 to 0.0006\n",
      "[85] : train loss 0.000717, val loss drop 0.0006 to 0.0005\n",
      "[88] : train loss 0.000943, val loss drop 0.0005 to 0.0004\n",
      "fold 2\n",
      "[1] : train loss 2.984785, val loss drop 10000000.0000 to 1.9835\n",
      "[2] : train loss 1.834152, val loss drop 1.9835 to 0.9116\n",
      "[3] : train loss 0.652220, val loss drop 0.9116 to 0.2942\n",
      "[6] : train loss 0.020008, val loss drop 0.2942 to 0.0937\n",
      "[7] : train loss 0.011024, val loss drop 0.0937 to 0.0069\n",
      "[8] : train loss 0.006435, val loss drop 0.0069 to 0.0048\n",
      "[9] : train loss 0.007399, val loss drop 0.0048 to 0.0038\n",
      "[14] : train loss 0.002876, val loss drop 0.0038 to 0.0018\n",
      "[15] : train loss 0.001943, val loss drop 0.0018 to 0.0016\n",
      "[20] : train loss 0.002696, val loss drop 0.0016 to 0.0009\n",
      "[33] : train loss 0.002410, val loss drop 0.0009 to 0.0008\n",
      "[47] : train loss 0.001269, val loss drop 0.0008 to 0.0006\n",
      "[91] : train loss 0.000614, val loss drop 0.0006 to 0.0003\n",
      "fold 3\n",
      "[1] : train loss 2.982869, val loss drop 10000000.0000 to 2.1626\n",
      "[2] : train loss 2.039972, val loss drop 2.1626 to 1.4183\n",
      "[3] : train loss 1.043998, val loss drop 1.4183 to 0.5652\n",
      "[4] : train loss 0.229405, val loss drop 0.5652 to 0.1597\n",
      "[6] : train loss 0.020781, val loss drop 0.1597 to 0.1563\n",
      "[7] : train loss 0.012830, val loss drop 0.1563 to 0.0130\n",
      "[8] : train loss 0.007487, val loss drop 0.0130 to 0.0119\n",
      "[10] : train loss 0.005191, val loss drop 0.0119 to 0.0045\n",
      "[12] : train loss 0.002882, val loss drop 0.0045 to 0.0030\n",
      "[20] : train loss 0.001818, val loss drop 0.0030 to 0.0018\n",
      "[25] : train loss 0.001750, val loss drop 0.0018 to 0.0012\n",
      "[29] : train loss 0.001478, val loss drop 0.0012 to 0.0010\n",
      "[44] : train loss 0.001729, val loss drop 0.0010 to 0.0010\n",
      "[56] : train loss 0.001192, val loss drop 0.0010 to 0.0010\n",
      "[61] : train loss 0.001308, val loss drop 0.0010 to 0.0008\n",
      "[70] : train loss 0.001110, val loss drop 0.0008 to 0.0006\n",
      "[76] : train loss 0.001814, val loss drop 0.0006 to 0.0005\n",
      "[82] : train loss 0.000851, val loss drop 0.0005 to 0.0004\n",
      "[92] : train loss 0.001133, val loss drop 0.0004 to 0.0003\n",
      "fold 4\n",
      "[1] : train loss 3.073203, val loss drop 10000000.0000 to 2.4033\n",
      "[2] : train loss 2.121946, val loss drop 2.4033 to 1.0347\n",
      "[3] : train loss 0.879711, val loss drop 1.0347 to 0.5437\n",
      "[4] : train loss 0.253572, val loss drop 0.5437 to 0.4073\n",
      "[5] : train loss 0.049461, val loss drop 0.4073 to 0.1042\n",
      "[6] : train loss 0.018259, val loss drop 0.1042 to 0.0544\n",
      "[7] : train loss 0.012315, val loss drop 0.0544 to 0.0087\n",
      "[8] : train loss 0.006494, val loss drop 0.0087 to 0.0053\n",
      "[10] : train loss 0.003566, val loss drop 0.0053 to 0.0032\n",
      "[18] : train loss 0.002600, val loss drop 0.0032 to 0.0026\n",
      "[24] : train loss 0.002542, val loss drop 0.0026 to 0.0014\n",
      "[31] : train loss 0.001139, val loss drop 0.0014 to 0.0013\n",
      "[38] : train loss 0.001922, val loss drop 0.0013 to 0.0009\n",
      "[40] : train loss 0.001497, val loss drop 0.0009 to 0.0009\n",
      "[55] : train loss 0.000705, val loss drop 0.0009 to 0.0007\n",
      "[56] : train loss 0.000640, val loss drop 0.0007 to 0.0005\n",
      "[76] : train loss 0.000759, val loss drop 0.0005 to 0.0005\n",
      "[80] : train loss 0.000611, val loss drop 0.0005 to 0.0004\n",
      "fold 5\n",
      "[1] : train loss 3.095000, val loss drop 10000000.0000 to 2.3733\n",
      "[2] : train loss 2.349694, val loss drop 2.3733 to 1.5467\n",
      "[3] : train loss 1.480114, val loss drop 1.5467 to 0.8764\n",
      "[4] : train loss 0.759767, val loss drop 0.8764 to 0.4563\n",
      "[5] : train loss 0.341672, val loss drop 0.4563 to 0.1815\n",
      "[6] : train loss 0.083304, val loss drop 0.1815 to 0.0538\n",
      "[7] : train loss 0.023380, val loss drop 0.0538 to 0.0392\n",
      "[8] : train loss 0.014111, val loss drop 0.0392 to 0.0181\n",
      "[9] : train loss 0.010084, val loss drop 0.0181 to 0.0070\n",
      "[11] : train loss 0.006244, val loss drop 0.0070 to 0.0053\n",
      "[14] : train loss 0.003581, val loss drop 0.0053 to 0.0048\n",
      "[15] : train loss 0.004035, val loss drop 0.0048 to 0.0033\n",
      "[18] : train loss 0.003766, val loss drop 0.0033 to 0.0019\n",
      "[32] : train loss 0.001774, val loss drop 0.0019 to 0.0012\n",
      "[34] : train loss 0.002155, val loss drop 0.0012 to 0.0009\n",
      "[43] : train loss 0.001492, val loss drop 0.0009 to 0.0008\n",
      "[59] : train loss 0.000476, val loss drop 0.0008 to 0.0006\n",
      "[63] : train loss 0.001077, val loss drop 0.0006 to 0.0006\n",
      "[73] : train loss 0.000825, val loss drop 0.0006 to 0.0004\n",
      "[95] : train loss 0.000869, val loss drop 0.0004 to 0.0004\n",
      "fold 6\n",
      "[1] : train loss 2.915508, val loss drop 10000000.0000 to 2.1269\n",
      "[2] : train loss 1.788130, val loss drop 2.1269 to 0.7173\n",
      "[3] : train loss 0.624947, val loss drop 0.7173 to 0.2556\n",
      "[4] : train loss 0.136257, val loss drop 0.2556 to 0.0926\n",
      "[6] : train loss 0.015207, val loss drop 0.0926 to 0.0186\n",
      "[7] : train loss 0.008634, val loss drop 0.0186 to 0.0079\n",
      "[9] : train loss 0.003670, val loss drop 0.0079 to 0.0056\n",
      "[12] : train loss 0.002699, val loss drop 0.0056 to 0.0034\n",
      "[13] : train loss 0.002301, val loss drop 0.0034 to 0.0020\n",
      "[17] : train loss 0.003691, val loss drop 0.0020 to 0.0016\n",
      "[20] : train loss 0.001893, val loss drop 0.0016 to 0.0015\n",
      "[24] : train loss 0.002631, val loss drop 0.0015 to 0.0012\n",
      "[33] : train loss 0.000787, val loss drop 0.0012 to 0.0010\n",
      "[62] : train loss 0.001235, val loss drop 0.0010 to 0.0008\n",
      "[67] : train loss 0.001263, val loss drop 0.0008 to 0.0005\n",
      "[93] : train loss 0.000769, val loss drop 0.0005 to 0.0005\n",
      "[96] : train loss 0.000567, val loss drop 0.0005 to 0.0004\n",
      "fold 7\n",
      "[1] : train loss 2.986498, val loss drop 10000000.0000 to 2.2604\n",
      "[2] : train loss 1.916857, val loss drop 2.2604 to 1.2481\n",
      "[3] : train loss 0.937585, val loss drop 1.2481 to 0.7560\n",
      "[4] : train loss 0.479002, val loss drop 0.7560 to 0.5467\n",
      "[5] : train loss 0.124541, val loss drop 0.5467 to 0.1168\n",
      "[6] : train loss 0.028786, val loss drop 0.1168 to 0.0511\n",
      "[7] : train loss 0.014040, val loss drop 0.0511 to 0.0187\n",
      "[8] : train loss 0.008740, val loss drop 0.0187 to 0.0113\n",
      "[9] : train loss 0.006157, val loss drop 0.0113 to 0.0047\n",
      "[11] : train loss 0.004920, val loss drop 0.0047 to 0.0045\n",
      "[13] : train loss 0.003865, val loss drop 0.0045 to 0.0032\n",
      "[16] : train loss 0.002194, val loss drop 0.0032 to 0.0018\n",
      "[17] : train loss 0.001814, val loss drop 0.0018 to 0.0013\n",
      "[23] : train loss 0.001897, val loss drop 0.0013 to 0.0012\n",
      "[24] : train loss 0.001348, val loss drop 0.0012 to 0.0012\n",
      "[31] : train loss 0.001257, val loss drop 0.0012 to 0.0008\n",
      "[50] : train loss 0.001240, val loss drop 0.0008 to 0.0007\n",
      "[56] : train loss 0.001183, val loss drop 0.0007 to 0.0004\n",
      "[80] : train loss 0.000632, val loss drop 0.0004 to 0.0003\n",
      "fold 8\n",
      "[1] : train loss 2.981261, val loss drop 10000000.0000 to 2.2960\n",
      "[2] : train loss 1.935623, val loss drop 2.2960 to 1.4690\n",
      "[3] : train loss 0.863577, val loss drop 1.4690 to 0.4219\n",
      "[5] : train loss 0.028996, val loss drop 0.4219 to 0.2546\n",
      "[6] : train loss 0.013520, val loss drop 0.2546 to 0.1144\n",
      "[7] : train loss 0.007310, val loss drop 0.1144 to 0.0414\n",
      "[8] : train loss 0.005938, val loss drop 0.0414 to 0.0116\n",
      "[9] : train loss 0.004518, val loss drop 0.0116 to 0.0062\n",
      "[10] : train loss 0.004255, val loss drop 0.0062 to 0.0047\n",
      "[11] : train loss 0.004964, val loss drop 0.0047 to 0.0040\n",
      "[14] : train loss 0.006517, val loss drop 0.0040 to 0.0040\n",
      "[16] : train loss 0.002211, val loss drop 0.0040 to 0.0017\n",
      "[19] : train loss 0.001821, val loss drop 0.0017 to 0.0014\n",
      "[23] : train loss 0.001294, val loss drop 0.0014 to 0.0011\n",
      "[35] : train loss 0.001114, val loss drop 0.0011 to 0.0007\n",
      "[68] : train loss 0.000924, val loss drop 0.0007 to 0.0006\n",
      "[82] : train loss 0.000717, val loss drop 0.0006 to 0.0004\n",
      "[97] : train loss 0.001086, val loss drop 0.0004 to 0.0003\n",
      "fold 9\n",
      "[1] : train loss 3.038905, val loss drop 10000000.0000 to 2.4386\n",
      "[2] : train loss 2.153491, val loss drop 2.4386 to 1.2245\n",
      "[3] : train loss 0.869757, val loss drop 1.2245 to 0.2873\n",
      "[4] : train loss 0.126947, val loss drop 0.2873 to 0.2726\n",
      "[5] : train loss 0.035757, val loss drop 0.2726 to 0.1782\n",
      "[6] : train loss 0.017272, val loss drop 0.1782 to 0.0485\n",
      "[7] : train loss 0.008846, val loss drop 0.0485 to 0.0172\n",
      "[8] : train loss 0.006111, val loss drop 0.0172 to 0.0041\n",
      "[9] : train loss 0.005011, val loss drop 0.0041 to 0.0030\n",
      "[11] : train loss 0.003179, val loss drop 0.0030 to 0.0027\n",
      "[16] : train loss 0.004256, val loss drop 0.0027 to 0.0013\n",
      "[23] : train loss 0.001691, val loss drop 0.0013 to 0.0009\n",
      "[28] : train loss 0.001532, val loss drop 0.0009 to 0.0008\n",
      "[29] : train loss 0.001687, val loss drop 0.0008 to 0.0008\n",
      "[36] : train loss 0.001573, val loss drop 0.0008 to 0.0008\n",
      "[39] : train loss 0.001476, val loss drop 0.0008 to 0.0006\n",
      "[59] : train loss 0.001729, val loss drop 0.0006 to 0.0005\n",
      "[75] : train loss 0.000629, val loss drop 0.0005 to 0.0004\n",
      "[91] : train loss 0.000758, val loss drop 0.0004 to 0.0004\n",
      "[98] : train loss 0.000530, val loss drop 0.0004 to 0.0002\n",
      "fold 10\n",
      "[1] : train loss 3.026450, val loss drop 10000000.0000 to 2.3930\n",
      "[2] : train loss 2.082253, val loss drop 2.3930 to 1.4102\n",
      "[3] : train loss 0.957669, val loss drop 1.4102 to 0.6767\n",
      "[4] : train loss 0.294551, val loss drop 0.6767 to 0.4133\n",
      "[5] : train loss 0.051001, val loss drop 0.4133 to 0.1299\n",
      "[7] : train loss 0.014805, val loss drop 0.1299 to 0.0533\n",
      "[8] : train loss 0.010715, val loss drop 0.0533 to 0.0230\n",
      "[9] : train loss 0.005709, val loss drop 0.0230 to 0.0045\n",
      "[12] : train loss 0.003951, val loss drop 0.0045 to 0.0024\n",
      "[14] : train loss 0.002474, val loss drop 0.0024 to 0.0021\n",
      "[15] : train loss 0.002237, val loss drop 0.0021 to 0.0016\n",
      "[21] : train loss 0.001681, val loss drop 0.0016 to 0.0013\n",
      "[28] : train loss 0.001245, val loss drop 0.0013 to 0.0009\n",
      "[37] : train loss 0.001965, val loss drop 0.0009 to 0.0006\n",
      "[59] : train loss 0.001366, val loss drop 0.0006 to 0.0005\n",
      "[63] : train loss 0.000985, val loss drop 0.0005 to 0.0003\n",
      "M train...\n",
      "fold 1\n",
      "[1] : train loss 71.425996, val loss drop 10000000.0000 to 32.3740\n",
      "[2] : train loss 18.379646, val loss drop 32.3740 to 13.9588\n",
      "[3] : train loss 3.370355, val loss drop 13.9588 to 13.0793\n",
      "[4] : train loss 1.643810, val loss drop 13.0793 to 11.1628\n",
      "[5] : train loss 0.893253, val loss drop 11.1628 to 2.8820\n",
      "[6] : train loss 0.685936, val loss drop 2.8820 to 1.4421\n",
      "[7] : train loss 0.460960, val loss drop 1.4421 to 0.8859\n",
      "[8] : train loss 0.461450, val loss drop 0.8859 to 0.4388\n",
      "[12] : train loss 0.214240, val loss drop 0.4388 to 0.4013\n",
      "[14] : train loss 0.229048, val loss drop 0.4013 to 0.1836\n",
      "[20] : train loss 0.162808, val loss drop 0.1836 to 0.1061\n",
      "[31] : train loss 0.107292, val loss drop 0.1061 to 0.0842\n",
      "[35] : train loss 0.168930, val loss drop 0.0842 to 0.0592\n",
      "[71] : train loss 0.115957, val loss drop 0.0592 to 0.0304\n",
      "fold 2\n",
      "[1] : train loss 47.206175, val loss drop 10000000.0000 to 16.1726\n",
      "[3] : train loss 1.734927, val loss drop 16.1726 to 9.2183\n",
      "[4] : train loss 0.793485, val loss drop 9.2183 to 2.4402\n",
      "[5] : train loss 0.613811, val loss drop 2.4402 to 1.3114\n",
      "[6] : train loss 0.453119, val loss drop 1.3114 to 0.3436\n",
      "[10] : train loss 0.293262, val loss drop 0.3436 to 0.2748\n",
      "[11] : train loss 0.407648, val loss drop 0.2748 to 0.1083\n",
      "[15] : train loss 0.182364, val loss drop 0.1083 to 0.1008\n",
      "[26] : train loss 0.143716, val loss drop 0.1008 to 0.0774\n",
      "[39] : train loss 0.153675, val loss drop 0.0774 to 0.0492\n",
      "[43] : train loss 0.188743, val loss drop 0.0492 to 0.0307\n",
      "[83] : train loss 0.137617, val loss drop 0.0307 to 0.0240\n",
      "[87] : train loss 0.065482, val loss drop 0.0240 to 0.0223\n",
      "[94] : train loss 0.195359, val loss drop 0.0223 to 0.0223\n",
      "fold 3\n",
      "[1] : train loss 43.300435, val loss drop 10000000.0000 to 14.3108\n",
      "[3] : train loss 1.473893, val loss drop 14.3108 to 7.0604\n",
      "[4] : train loss 0.830515, val loss drop 7.0604 to 4.1462\n",
      "[5] : train loss 0.577179, val loss drop 4.1462 to 1.8086\n",
      "[6] : train loss 0.456326, val loss drop 1.8086 to 0.5050\n",
      "[7] : train loss 0.316891, val loss drop 0.5050 to 0.3921\n",
      "[10] : train loss 0.440162, val loss drop 0.3921 to 0.1358\n",
      "[15] : train loss 0.512826, val loss drop 0.1358 to 0.1156\n",
      "[24] : train loss 0.129439, val loss drop 0.1156 to 0.0584\n",
      "[38] : train loss 0.280967, val loss drop 0.0584 to 0.0270\n",
      "[97] : train loss 0.108238, val loss drop 0.0270 to 0.0244\n",
      "fold 4\n",
      "[1] : train loss 82.059494, val loss drop 10000000.0000 to 41.0263\n",
      "[2] : train loss 29.116908, val loss drop 41.0263 to 8.3640\n",
      "[3] : train loss 5.013402, val loss drop 8.3640 to 5.4092\n",
      "[6] : train loss 0.767843, val loss drop 5.4092 to 1.6722\n",
      "[7] : train loss 0.503088, val loss drop 1.6722 to 0.3374\n",
      "[11] : train loss 0.346653, val loss drop 0.3374 to 0.3186\n",
      "[13] : train loss 0.296997, val loss drop 0.3186 to 0.1292\n",
      "[17] : train loss 0.260668, val loss drop 0.1292 to 0.0996\n",
      "[35] : train loss 0.183398, val loss drop 0.0996 to 0.0780\n",
      "[37] : train loss 0.113950, val loss drop 0.0780 to 0.0500\n",
      "[48] : train loss 0.124771, val loss drop 0.0500 to 0.0221\n",
      "fold 5\n",
      "[1] : train loss 53.141923, val loss drop 10000000.0000 to 26.2602\n",
      "[4] : train loss 1.050790, val loss drop 26.2602 to 5.6902\n",
      "[5] : train loss 0.740844, val loss drop 5.6902 to 1.4527\n",
      "[6] : train loss 0.489007, val loss drop 1.4527 to 1.3897\n",
      "[7] : train loss 0.416439, val loss drop 1.3897 to 0.8727\n",
      "[10] : train loss 0.395473, val loss drop 0.8727 to 0.3463\n",
      "[11] : train loss 0.240814, val loss drop 0.3463 to 0.1053\n",
      "[21] : train loss 0.131454, val loss drop 0.1053 to 0.0480\n",
      "[25] : train loss 0.118026, val loss drop 0.0480 to 0.0443\n",
      "[32] : train loss 0.102246, val loss drop 0.0443 to 0.0396\n",
      "[68] : train loss 0.060199, val loss drop 0.0396 to 0.0301\n",
      "[70] : train loss 0.108028, val loss drop 0.0301 to 0.0201\n",
      "[71] : train loss 0.147992, val loss drop 0.0201 to 0.0200\n",
      "fold 6\n",
      "[1] : train loss 73.105539, val loss drop 10000000.0000 to 27.9515\n",
      "[2] : train loss 19.700001, val loss drop 27.9515 to 12.8742\n",
      "[4] : train loss 1.681317, val loss drop 12.8742 to 11.7731\n",
      "[5] : train loss 0.935968, val loss drop 11.7731 to 2.0585\n",
      "[6] : train loss 0.604270, val loss drop 2.0585 to 0.5975\n",
      "[9] : train loss 0.328947, val loss drop 0.5975 to 0.2787\n",
      "[11] : train loss 0.147059, val loss drop 0.2787 to 0.1574\n",
      "[26] : train loss 0.207374, val loss drop 0.1574 to 0.0960\n",
      "[32] : train loss 0.285938, val loss drop 0.0960 to 0.0530\n",
      "[41] : train loss 0.360091, val loss drop 0.0530 to 0.0354\n",
      "[60] : train loss 0.117357, val loss drop 0.0354 to 0.0215\n",
      "fold 7\n",
      "[1] : train loss 63.433049, val loss drop 10000000.0000 to 25.1062\n",
      "[2] : train loss 11.123720, val loss drop 25.1062 to 22.1906\n",
      "[4] : train loss 1.754502, val loss drop 22.1906 to 8.5146\n",
      "[5] : train loss 1.090197, val loss drop 8.5146 to 3.1492\n",
      "[6] : train loss 0.711777, val loss drop 3.1492 to 1.3702\n",
      "[7] : train loss 0.518314, val loss drop 1.3702 to 0.3806\n",
      "[8] : train loss 0.363154, val loss drop 0.3806 to 0.3082\n",
      "[14] : train loss 0.288564, val loss drop 0.3082 to 0.2292\n",
      "[18] : train loss 0.170510, val loss drop 0.2292 to 0.0798\n",
      "[39] : train loss 0.201138, val loss drop 0.0798 to 0.0367\n",
      "[84] : train loss 0.074582, val loss drop 0.0367 to 0.0282\n",
      "fold 8\n",
      "[1] : train loss 81.416070, val loss drop 10000000.0000 to 53.5871\n",
      "[2] : train loss 32.375505, val loss drop 53.5871 to 11.1562\n",
      "[3] : train loss 5.136430, val loss drop 11.1562 to 4.3331\n",
      "[5] : train loss 1.064910, val loss drop 4.3331 to 2.3198\n",
      "[6] : train loss 0.593681, val loss drop 2.3198 to 2.1414\n",
      "[7] : train loss 0.456517, val loss drop 2.1414 to 0.4050\n",
      "[9] : train loss 0.321060, val loss drop 0.4050 to 0.1552\n",
      "[15] : train loss 0.231977, val loss drop 0.1552 to 0.0882\n",
      "[25] : train loss 0.166337, val loss drop 0.0882 to 0.0730\n",
      "[29] : train loss 0.097068, val loss drop 0.0730 to 0.0712\n",
      "[37] : train loss 0.381817, val loss drop 0.0712 to 0.0646\n",
      "[38] : train loss 0.177529, val loss drop 0.0646 to 0.0403\n",
      "[48] : train loss 0.106750, val loss drop 0.0403 to 0.0245\n",
      "[73] : train loss 0.117170, val loss drop 0.0245 to 0.0229\n",
      "fold 9\n",
      "[1] : train loss 61.259990, val loss drop 10000000.0000 to 38.9148\n",
      "[2] : train loss 11.334188, val loss drop 38.9148 to 34.3090\n",
      "[3] : train loss 2.787451, val loss drop 34.3090 to 11.1982\n",
      "[4] : train loss 1.264641, val loss drop 11.1982 to 3.2285\n",
      "[6] : train loss 0.502881, val loss drop 3.2285 to 2.1356\n",
      "[7] : train loss 0.385791, val loss drop 2.1356 to 0.4500\n",
      "[9] : train loss 0.287976, val loss drop 0.4500 to 0.3300\n",
      "[12] : train loss 0.262575, val loss drop 0.3300 to 0.3067\n",
      "[13] : train loss 0.394450, val loss drop 0.3067 to 0.2831\n",
      "[16] : train loss 0.265879, val loss drop 0.2831 to 0.1145\n",
      "[20] : train loss 0.266841, val loss drop 0.1145 to 0.0623\n",
      "[27] : train loss 0.119403, val loss drop 0.0623 to 0.0358\n",
      "[34] : train loss 0.223865, val loss drop 0.0358 to 0.0302\n",
      "[47] : train loss 0.124366, val loss drop 0.0302 to 0.0281\n",
      "[54] : train loss 0.103281, val loss drop 0.0281 to 0.0272\n",
      "[56] : train loss 0.280700, val loss drop 0.0272 to 0.0230\n",
      "fold 10\n",
      "[1] : train loss 60.593193, val loss drop 10000000.0000 to 49.0562\n",
      "[2] : train loss 10.341467, val loss drop 49.0562 to 19.6331\n",
      "[3] : train loss 2.799189, val loss drop 19.6331 to 8.9258\n",
      "[4] : train loss 1.267455, val loss drop 8.9258 to 2.0237\n",
      "[6] : train loss 0.670101, val loss drop 2.0237 to 0.6172\n",
      "[8] : train loss 0.484910, val loss drop 0.6172 to 0.2813\n",
      "[9] : train loss 0.332699, val loss drop 0.2813 to 0.1622\n",
      "[10] : train loss 0.335564, val loss drop 0.1622 to 0.1403\n",
      "[19] : train loss 0.208457, val loss drop 0.1403 to 0.0595\n",
      "[30] : train loss 0.126152, val loss drop 0.0595 to 0.0538\n",
      "[34] : train loss 0.285449, val loss drop 0.0538 to 0.0447\n",
      "[36] : train loss 0.083853, val loss drop 0.0447 to 0.0305\n",
      "[82] : train loss 0.108770, val loss drop 0.0305 to 0.0296\n",
      "[85] : train loss 0.125953, val loss drop 0.0296 to 0.0236\n",
      "V train...\n",
      "fold 1\n",
      "[1] : train loss 3.498565, val loss drop 10000000.0000 to 0.7184\n",
      "[2] : train loss 0.215912, val loss drop 0.7184 to 0.1506\n",
      "[3] : train loss 0.076097, val loss drop 0.1506 to 0.0468\n",
      "[4] : train loss 0.042781, val loss drop 0.0468 to 0.0354\n",
      "[5] : train loss 0.022489, val loss drop 0.0354 to 0.0225\n",
      "[6] : train loss 0.014355, val loss drop 0.0225 to 0.0195\n",
      "[7] : train loss 0.011739, val loss drop 0.0195 to 0.0127\n",
      "[9] : train loss 0.007099, val loss drop 0.0127 to 0.0102\n",
      "[11] : train loss 0.006308, val loss drop 0.0102 to 0.0100\n",
      "[13] : train loss 0.005836, val loss drop 0.0100 to 0.0074\n",
      "[17] : train loss 0.004639, val loss drop 0.0074 to 0.0063\n",
      "[22] : train loss 0.003423, val loss drop 0.0063 to 0.0060\n",
      "[32] : train loss 0.002200, val loss drop 0.0060 to 0.0050\n",
      "[35] : train loss 0.003995, val loss drop 0.0050 to 0.0048\n",
      "[38] : train loss 0.001815, val loss drop 0.0048 to 0.0042\n",
      "[52] : train loss 0.001550, val loss drop 0.0042 to 0.0038\n",
      "[60] : train loss 0.002113, val loss drop 0.0038 to 0.0037\n",
      "[63] : train loss 0.001261, val loss drop 0.0037 to 0.0034\n",
      "[74] : train loss 0.001167, val loss drop 0.0034 to 0.0031\n",
      "[78] : train loss 0.002333, val loss drop 0.0031 to 0.0030\n",
      "[94] : train loss 0.001183, val loss drop 0.0030 to 0.0029\n",
      "fold 2\n",
      "[1] : train loss 3.954753, val loss drop 10000000.0000 to 1.0102\n",
      "[2] : train loss 0.330294, val loss drop 1.0102 to 0.4182\n",
      "[3] : train loss 0.112813, val loss drop 0.4182 to 0.1122\n",
      "[4] : train loss 0.053444, val loss drop 0.1122 to 0.0659\n",
      "[5] : train loss 0.033281, val loss drop 0.0659 to 0.0452\n",
      "[6] : train loss 0.023203, val loss drop 0.0452 to 0.0253\n",
      "[7] : train loss 0.017406, val loss drop 0.0253 to 0.0207\n",
      "[8] : train loss 0.013912, val loss drop 0.0207 to 0.0153\n",
      "[11] : train loss 0.009105, val loss drop 0.0153 to 0.0121\n",
      "[15] : train loss 0.007784, val loss drop 0.0121 to 0.0114\n",
      "[16] : train loss 0.006277, val loss drop 0.0114 to 0.0096\n",
      "[18] : train loss 0.005328, val loss drop 0.0096 to 0.0080\n",
      "[20] : train loss 0.006418, val loss drop 0.0080 to 0.0073\n",
      "[23] : train loss 0.006009, val loss drop 0.0073 to 0.0062\n",
      "[32] : train loss 0.003555, val loss drop 0.0062 to 0.0061\n",
      "[34] : train loss 0.004295, val loss drop 0.0061 to 0.0052\n",
      "[41] : train loss 0.003617, val loss drop 0.0052 to 0.0048\n",
      "[51] : train loss 0.007427, val loss drop 0.0048 to 0.0044\n",
      "[53] : train loss 0.004266, val loss drop 0.0044 to 0.0040\n",
      "[60] : train loss 0.004376, val loss drop 0.0040 to 0.0037\n",
      "[62] : train loss 0.001935, val loss drop 0.0037 to 0.0035\n",
      "[70] : train loss 0.001839, val loss drop 0.0035 to 0.0030\n",
      "[78] : train loss 0.001730, val loss drop 0.0030 to 0.0026\n",
      "[100] : train loss 0.002143, val loss drop 0.0026 to 0.0026\n",
      "fold 3\n",
      "[1] : train loss 4.022215, val loss drop 10000000.0000 to 0.8674\n",
      "[2] : train loss 0.139302, val loss drop 0.8674 to 0.1375\n",
      "[3] : train loss 0.055856, val loss drop 0.1375 to 0.0487\n",
      "[4] : train loss 0.032483, val loss drop 0.0487 to 0.0280\n",
      "[5] : train loss 0.019582, val loss drop 0.0280 to 0.0169\n",
      "[6] : train loss 0.014154, val loss drop 0.0169 to 0.0140\n",
      "[7] : train loss 0.010445, val loss drop 0.0140 to 0.0131\n",
      "[9] : train loss 0.007114, val loss drop 0.0131 to 0.0084\n",
      "[12] : train loss 0.005485, val loss drop 0.0084 to 0.0077\n",
      "[14] : train loss 0.006075, val loss drop 0.0077 to 0.0071\n",
      "[16] : train loss 0.005077, val loss drop 0.0071 to 0.0069\n",
      "[20] : train loss 0.005925, val loss drop 0.0069 to 0.0053\n",
      "[21] : train loss 0.003821, val loss drop 0.0053 to 0.0048\n",
      "[23] : train loss 0.003212, val loss drop 0.0048 to 0.0044\n",
      "[28] : train loss 0.004017, val loss drop 0.0044 to 0.0038\n",
      "[39] : train loss 0.001928, val loss drop 0.0038 to 0.0035\n",
      "[43] : train loss 0.002475, val loss drop 0.0035 to 0.0025\n",
      "[65] : train loss 0.001108, val loss drop 0.0025 to 0.0022\n",
      "[76] : train loss 0.001250, val loss drop 0.0022 to 0.0019\n",
      "[91] : train loss 0.001251, val loss drop 0.0019 to 0.0018\n",
      "fold 4\n",
      "[1] : train loss 2.532672, val loss drop 10000000.0000 to 0.5184\n",
      "[2] : train loss 0.181327, val loss drop 0.5184 to 0.1073\n",
      "[3] : train loss 0.071210, val loss drop 0.1073 to 0.0543\n",
      "[4] : train loss 0.035022, val loss drop 0.0543 to 0.0398\n",
      "[5] : train loss 0.021607, val loss drop 0.0398 to 0.0269\n",
      "[6] : train loss 0.014512, val loss drop 0.0269 to 0.0165\n",
      "[7] : train loss 0.010696, val loss drop 0.0165 to 0.0146\n",
      "[8] : train loss 0.008633, val loss drop 0.0146 to 0.0134\n",
      "[9] : train loss 0.007031, val loss drop 0.0134 to 0.0125\n",
      "[10] : train loss 0.007540, val loss drop 0.0125 to 0.0108\n",
      "[11] : train loss 0.006434, val loss drop 0.0108 to 0.0084\n",
      "[15] : train loss 0.003479, val loss drop 0.0084 to 0.0072\n",
      "[17] : train loss 0.003806, val loss drop 0.0072 to 0.0064\n",
      "[18] : train loss 0.003045, val loss drop 0.0064 to 0.0048\n",
      "[24] : train loss 0.002032, val loss drop 0.0048 to 0.0047\n",
      "[30] : train loss 0.006749, val loss drop 0.0047 to 0.0038\n",
      "[32] : train loss 0.002074, val loss drop 0.0038 to 0.0036\n",
      "[39] : train loss 0.001688, val loss drop 0.0036 to 0.0031\n",
      "[42] : train loss 0.001165, val loss drop 0.0031 to 0.0023\n",
      "[58] : train loss 0.001609, val loss drop 0.0023 to 0.0022\n",
      "[79] : train loss 0.001343, val loss drop 0.0022 to 0.0021\n",
      "[80] : train loss 0.000978, val loss drop 0.0021 to 0.0017\n",
      "[100] : train loss 0.000901, val loss drop 0.0017 to 0.0017\n",
      "fold 5\n",
      "[1] : train loss 3.235959, val loss drop 10000000.0000 to 0.8579\n",
      "[2] : train loss 0.428629, val loss drop 0.8579 to 0.2837\n",
      "[3] : train loss 0.134496, val loss drop 0.2837 to 0.1073\n",
      "[4] : train loss 0.073820, val loss drop 0.1073 to 0.0714\n",
      "[5] : train loss 0.039708, val loss drop 0.0714 to 0.0481\n",
      "[6] : train loss 0.023656, val loss drop 0.0481 to 0.0438\n",
      "[7] : train loss 0.016997, val loss drop 0.0438 to 0.0269\n",
      "[9] : train loss 0.013592, val loss drop 0.0269 to 0.0231\n",
      "[11] : train loss 0.008726, val loss drop 0.0231 to 0.0223\n",
      "[12] : train loss 0.008394, val loss drop 0.0223 to 0.0204\n",
      "[13] : train loss 0.008437, val loss drop 0.0204 to 0.0202\n",
      "[14] : train loss 0.007394, val loss drop 0.0202 to 0.0179\n",
      "[16] : train loss 0.006222, val loss drop 0.0179 to 0.0178\n",
      "[18] : train loss 0.005470, val loss drop 0.0178 to 0.0173\n",
      "[20] : train loss 0.006969, val loss drop 0.0173 to 0.0153\n",
      "[23] : train loss 0.004253, val loss drop 0.0153 to 0.0141\n",
      "[26] : train loss 0.006266, val loss drop 0.0141 to 0.0129\n",
      "[28] : train loss 0.005850, val loss drop 0.0129 to 0.0119\n",
      "[30] : train loss 0.005487, val loss drop 0.0119 to 0.0109\n",
      "[36] : train loss 0.005328, val loss drop 0.0109 to 0.0091\n",
      "[40] : train loss 0.003308, val loss drop 0.0091 to 0.0088\n",
      "[43] : train loss 0.003146, val loss drop 0.0088 to 0.0084\n",
      "[52] : train loss 0.002612, val loss drop 0.0084 to 0.0077\n",
      "[55] : train loss 0.003698, val loss drop 0.0077 to 0.0077\n",
      "[66] : train loss 0.002698, val loss drop 0.0077 to 0.0074\n",
      "[71] : train loss 0.002820, val loss drop 0.0074 to 0.0061\n",
      "[80] : train loss 0.002544, val loss drop 0.0061 to 0.0055\n",
      "[93] : train loss 0.001671, val loss drop 0.0055 to 0.0054\n",
      "[98] : train loss 0.001329, val loss drop 0.0054 to 0.0047\n",
      "fold 6\n",
      "[1] : train loss 5.602064, val loss drop 10000000.0000 to 1.6704\n",
      "[2] : train loss 0.569776, val loss drop 1.6704 to 0.4942\n",
      "[3] : train loss 0.212118, val loss drop 0.4942 to 0.1651\n",
      "[4] : train loss 0.104805, val loss drop 0.1651 to 0.0974\n",
      "[5] : train loss 0.062541, val loss drop 0.0974 to 0.0545\n",
      "[6] : train loss 0.040411, val loss drop 0.0545 to 0.0373\n",
      "[7] : train loss 0.024798, val loss drop 0.0373 to 0.0367\n",
      "[9] : train loss 0.019828, val loss drop 0.0367 to 0.0366\n",
      "[10] : train loss 0.016979, val loss drop 0.0366 to 0.0301\n",
      "[14] : train loss 0.010528, val loss drop 0.0301 to 0.0276\n",
      "[15] : train loss 0.011937, val loss drop 0.0276 to 0.0249\n",
      "[16] : train loss 0.009691, val loss drop 0.0249 to 0.0216\n",
      "[26] : train loss 0.006946, val loss drop 0.0216 to 0.0175\n",
      "[27] : train loss 0.005572, val loss drop 0.0175 to 0.0144\n",
      "[42] : train loss 0.003992, val loss drop 0.0144 to 0.0144\n",
      "[49] : train loss 0.004343, val loss drop 0.0144 to 0.0128\n",
      "[58] : train loss 0.005871, val loss drop 0.0128 to 0.0120\n",
      "[60] : train loss 0.005336, val loss drop 0.0120 to 0.0115\n",
      "[68] : train loss 0.004546, val loss drop 0.0115 to 0.0107\n",
      "[78] : train loss 0.005007, val loss drop 0.0107 to 0.0100\n",
      "[87] : train loss 0.002066, val loss drop 0.0100 to 0.0090\n",
      "[88] : train loss 0.002242, val loss drop 0.0090 to 0.0083\n",
      "[96] : train loss 0.003412, val loss drop 0.0083 to 0.0076\n",
      "fold 7\n",
      "[1] : train loss 2.381659, val loss drop 10000000.0000 to 0.5808\n",
      "[2] : train loss 0.209323, val loss drop 0.5808 to 0.1666\n",
      "[3] : train loss 0.075392, val loss drop 0.1666 to 0.0401\n",
      "[4] : train loss 0.033841, val loss drop 0.0401 to 0.0324\n",
      "[5] : train loss 0.021547, val loss drop 0.0324 to 0.0242\n",
      "[6] : train loss 0.014301, val loss drop 0.0242 to 0.0228\n",
      "[7] : train loss 0.012138, val loss drop 0.0228 to 0.0187\n",
      "[8] : train loss 0.010616, val loss drop 0.0187 to 0.0142\n",
      "[9] : train loss 0.007580, val loss drop 0.0142 to 0.0120\n",
      "[11] : train loss 0.005499, val loss drop 0.0120 to 0.0087\n",
      "[23] : train loss 0.003494, val loss drop 0.0087 to 0.0073\n",
      "[26] : train loss 0.003599, val loss drop 0.0073 to 0.0055\n",
      "[41] : train loss 0.002113, val loss drop 0.0055 to 0.0051\n",
      "[47] : train loss 0.002677, val loss drop 0.0051 to 0.0046\n",
      "[48] : train loss 0.003247, val loss drop 0.0046 to 0.0045\n",
      "[69] : train loss 0.001661, val loss drop 0.0045 to 0.0035\n",
      "[83] : train loss 0.002962, val loss drop 0.0035 to 0.0034\n",
      "[95] : train loss 0.001590, val loss drop 0.0034 to 0.0033\n",
      "fold 8\n",
      "[1] : train loss 5.859980, val loss drop 10000000.0000 to 1.0657\n",
      "[2] : train loss 0.286065, val loss drop 1.0657 to 0.1800\n",
      "[3] : train loss 0.095335, val loss drop 0.1800 to 0.0799\n",
      "[4] : train loss 0.048619, val loss drop 0.0799 to 0.0531\n",
      "[5] : train loss 0.030147, val loss drop 0.0531 to 0.0365\n",
      "[6] : train loss 0.020790, val loss drop 0.0365 to 0.0216\n",
      "[7] : train loss 0.016621, val loss drop 0.0216 to 0.0198\n",
      "[10] : train loss 0.010719, val loss drop 0.0198 to 0.0143\n",
      "[12] : train loss 0.007699, val loss drop 0.0143 to 0.0139\n",
      "[14] : train loss 0.007183, val loss drop 0.0139 to 0.0093\n",
      "[18] : train loss 0.005025, val loss drop 0.0093 to 0.0075\n",
      "[25] : train loss 0.003183, val loss drop 0.0075 to 0.0074\n",
      "[26] : train loss 0.003247, val loss drop 0.0074 to 0.0071\n",
      "[31] : train loss 0.004851, val loss drop 0.0071 to 0.0059\n",
      "[35] : train loss 0.002387, val loss drop 0.0059 to 0.0047\n",
      "[40] : train loss 0.003611, val loss drop 0.0047 to 0.0038\n",
      "[47] : train loss 0.003172, val loss drop 0.0038 to 0.0036\n",
      "[52] : train loss 0.001522, val loss drop 0.0036 to 0.0029\n",
      "[58] : train loss 0.001563, val loss drop 0.0029 to 0.0028\n",
      "[79] : train loss 0.003362, val loss drop 0.0028 to 0.0028\n",
      "[80] : train loss 0.001590, val loss drop 0.0028 to 0.0025\n",
      "fold 9\n",
      "[1] : train loss 3.759192, val loss drop 10000000.0000 to 0.9078\n",
      "[2] : train loss 0.360492, val loss drop 0.9078 to 0.3334\n",
      "[3] : train loss 0.147045, val loss drop 0.3334 to 0.1241\n",
      "[4] : train loss 0.074013, val loss drop 0.1241 to 0.0788\n",
      "[5] : train loss 0.041543, val loss drop 0.0788 to 0.0511\n",
      "[6] : train loss 0.027070, val loss drop 0.0511 to 0.0379\n",
      "[7] : train loss 0.019494, val loss drop 0.0379 to 0.0263\n",
      "[9] : train loss 0.013217, val loss drop 0.0263 to 0.0208\n",
      "[11] : train loss 0.008898, val loss drop 0.0208 to 0.0202\n",
      "[12] : train loss 0.008023, val loss drop 0.0202 to 0.0164\n",
      "[16] : train loss 0.007233, val loss drop 0.0164 to 0.0161\n",
      "[17] : train loss 0.005418, val loss drop 0.0161 to 0.0155\n",
      "[18] : train loss 0.005083, val loss drop 0.0155 to 0.0133\n",
      "[24] : train loss 0.004457, val loss drop 0.0133 to 0.0113\n",
      "[28] : train loss 0.004441, val loss drop 0.0113 to 0.0102\n",
      "[38] : train loss 0.003707, val loss drop 0.0102 to 0.0102\n",
      "[41] : train loss 0.005226, val loss drop 0.0102 to 0.0089\n",
      "[46] : train loss 0.005174, val loss drop 0.0089 to 0.0079\n",
      "[54] : train loss 0.005902, val loss drop 0.0079 to 0.0078\n",
      "[57] : train loss 0.003101, val loss drop 0.0078 to 0.0065\n",
      "[67] : train loss 0.002139, val loss drop 0.0065 to 0.0051\n",
      "fold 10\n",
      "[1] : train loss 5.928456, val loss drop 10000000.0000 to 0.8376\n",
      "[2] : train loss 0.363714, val loss drop 0.8376 to 0.1939\n",
      "[3] : train loss 0.122300, val loss drop 0.1939 to 0.1531\n",
      "[4] : train loss 0.066329, val loss drop 0.1531 to 0.0593\n",
      "[5] : train loss 0.038236, val loss drop 0.0593 to 0.0325\n",
      "[7] : train loss 0.018411, val loss drop 0.0325 to 0.0265\n",
      "[8] : train loss 0.014431, val loss drop 0.0265 to 0.0251\n",
      "[9] : train loss 0.012324, val loss drop 0.0251 to 0.0197\n",
      "[10] : train loss 0.009746, val loss drop 0.0197 to 0.0165\n",
      "[14] : train loss 0.007056, val loss drop 0.0165 to 0.0164\n",
      "[15] : train loss 0.006205, val loss drop 0.0164 to 0.0148\n",
      "[16] : train loss 0.005894, val loss drop 0.0148 to 0.0141\n",
      "[17] : train loss 0.005103, val loss drop 0.0141 to 0.0122\n",
      "[18] : train loss 0.005954, val loss drop 0.0122 to 0.0110\n",
      "[22] : train loss 0.004135, val loss drop 0.0110 to 0.0107\n",
      "[24] : train loss 0.004258, val loss drop 0.0107 to 0.0107\n",
      "[26] : train loss 0.006374, val loss drop 0.0107 to 0.0101\n",
      "[30] : train loss 0.003748, val loss drop 0.0101 to 0.0075\n",
      "[35] : train loss 0.002408, val loss drop 0.0075 to 0.0061\n",
      "[45] : train loss 0.002735, val loss drop 0.0061 to 0.0057\n",
      "[68] : train loss 0.003134, val loss drop 0.0057 to 0.0057\n",
      "[70] : train loss 0.002140, val loss drop 0.0057 to 0.0052\n",
      "[81] : train loss 0.001337, val loss drop 0.0052 to 0.0043\n",
      "[88] : train loss 0.001656, val loss drop 0.0043 to 0.0042\n",
      "[89] : train loss 0.002054, val loss drop 0.0042 to 0.0040\n"
     ]
    }
   ],
   "source": [
    "loss_per_model = {}\n",
    "for name in ['XY','M','V']:\n",
    "    print('{} train...'.format(name))\n",
    "    \n",
    "    # make dataset\n",
    "    train_target = train_t[list(name)].values#.astype(np.float32)\n",
    "\n",
    "    # trainx, valx, trainy, valy = train_test_split(train_f, train_target, test_size = 0.2, shuffle = True, random_state = 38)\n",
    "    fold = KFold(nfold, shuffle = True, random_state= 25)\n",
    "    loss_per_cv = []\n",
    "    for i, (train_idx, val_idx) in enumerate(fold.split(train_f, y = train_target)):\n",
    "        print('fold {}'.format(i+1))\n",
    "        trainx = train_f[train_idx]\n",
    "        valx = train_f[val_idx]\n",
    "        trainy = train_target[train_idx]\n",
    "        valy = train_target[val_idx]\n",
    "        \n",
    "        train_dataset = dfDataset(trainx.astype(np.float32), trainy)\n",
    "        train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "        val_dataset = dfDataset(valx.astype(np.float32), valy)\n",
    "        val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "        #fc = classifier([128, 64, 32, 16], input_size = 256*2*5, output_size = len(name))\n",
    "        #conv = conv_block([32, 64, 128, 256, 256, 256, 256], [1, 375, 5], (3, 1))\n",
    "        conv = conv_block([16, 32, 64, 128, 256, 256, 256], [1, 375, 5], (3, 1))\n",
    "        fc = classifier([128, 64, 32, 16], input_size = 256*1*5, output_size = len(name))\n",
    "        # define model\n",
    "        model = cnn_model(conv, fc)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = base_lr)\n",
    "\n",
    "        if name == 'XY':\n",
    "            criterion = E1_loss\n",
    "        else:\n",
    "            criterion = E2_loss\n",
    "\n",
    "        model = model.cuda()\n",
    "        if initialize:\n",
    "            model.apply(weights_init)\n",
    "\n",
    "        curr_loss = 1e+7\n",
    "        os.makedirs(save_path) if not os.path.exists(save_path) else None\n",
    "        #train\n",
    "        for ep in range(1, EPOCH + 1):\n",
    "            model.train()\n",
    "            loss = train_model(model, train_loader, criterion, optimizer, criterion)\n",
    "            model.eval()\n",
    "            val_loss =eval_model(model, val_loader, criterion)\n",
    "            if curr_loss > val_loss:\n",
    "                print('[{}] : train loss {:4f}, val loss drop {:.4f} to {:.4f}'.format(ep, np.mean(loss), curr_loss, val_loss))\n",
    "                curr_loss = val_loss\n",
    "                torch.save(model.state_dict(), os.path.join(save_path, 'model_{}_fold{}.pt'.format(name, i+1)))\n",
    "        loss_per_cv.append(curr_loss)\n",
    "    loss_per_model[name] = loss_per_cv           \n",
    "            #else:\n",
    "                #print('[{}] : train loss {:.4f}, val loss {:.4f}, not drop'.format(ep, np.mean(loss), val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_path, 'loss_info.json'), 'w') as f:\n",
    "    for k in loss_per_model:\n",
    "        loss_per_model[k] = np.mean(loss_per_model[k])\n",
    "    f.write(json.dumps(loss_per_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(os.path.join(root_dir, 'sample_submission.csv'))\n",
    "for name in ['XY','M','V']:\n",
    "    fc = classifier([128, 64, 32, 16], input_size = 512*3*5, output_size = len(name))\n",
    "    conv = conv_block([16, 32, 64, 128, 256, 512], [1, 375, 5], (3, 1))\n",
    "    # define model\n",
    "    model = cnn_model(conv, fc)\n",
    "    pred_array = []\n",
    "    for i in range(1, nfold + 1):\n",
    "        model.load_state_dict(torch.load(os.path.join(save_path, 'model_{}_fold{}.pt'.format(name, i))))\n",
    "        model = model.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predict = model(test_f.cuda())\n",
    "        pred_array.append(predict.detach().cpu().numpy())\n",
    "    submission[list(name)] = np.mean(pred_array, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>M</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2800</td>\n",
       "      <td>-261.139008</td>\n",
       "      <td>-39.881229</td>\n",
       "      <td>111.966736</td>\n",
       "      <td>0.434986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2801</td>\n",
       "      <td>316.171234</td>\n",
       "      <td>-286.514954</td>\n",
       "      <td>90.317627</td>\n",
       "      <td>0.421709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2802</td>\n",
       "      <td>-233.366653</td>\n",
       "      <td>128.657593</td>\n",
       "      <td>28.895294</td>\n",
       "      <td>0.357899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2803</td>\n",
       "      <td>160.693039</td>\n",
       "      <td>276.158539</td>\n",
       "      <td>27.653961</td>\n",
       "      <td>0.372838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2804</td>\n",
       "      <td>-170.325470</td>\n",
       "      <td>187.950928</td>\n",
       "      <td>133.650543</td>\n",
       "      <td>0.478190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id           X           Y           M         V\n",
       "0  2800 -261.139008  -39.881229  111.966736  0.434986\n",
       "1  2801  316.171234 -286.514954   90.317627  0.421709\n",
       "2  2802 -233.366653  128.657593   28.895294  0.357899\n",
       "3  2803  160.693039  276.158539   27.653961  0.372838\n",
       "4  2804 -170.325470  187.950928  133.650543  0.478190"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(os.path.join(save_path, 'submit.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 10)\n",
    "y = torch.randn(1, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
